---
title: "Motion Planning for Physical AI – Trajectory Optimization and Control"
description: "Advanced motion planning techniques for Physical AI systems, including trajectory optimization, model predictive control, and real-time motion planning for dynamic environments."
tags: ["motion-planning", "trajectory-optimization", "control", "physical-ai", "robotics"]
sidebar_label: "Chapter 4: Motion Planning for Physical AI"
slug: "/modules/module3/chapter4"
keywords: ["Motion Planning", "Trajectory Optimization", "Robot Control", "Physical AI Motion", "Model Predictive Control"]
---

# Motion Planning for Physical AI – Trajectory Optimization and Control

## Learning Objectives

By the end of this chapter, you will be able to:
- Implement trajectory optimization algorithms for robotic motion planning
- Apply model predictive control (MPC) for real-time motion control
- Design motion planners that account for robot dynamics and constraints
- Integrate perception and planning for dynamic obstacle avoidance
- Evaluate motion planning algorithms based on computational efficiency and safety
- Design robust control systems for physical robot execution

## Introduction

Motion planning in Physical AI systems bridges the gap between abstract path planning and the physical execution of movements. While path planning determines *where* to go, motion planning determines *how* to move the robot's body to achieve the desired motion while respecting physical constraints, dynamics, and safety requirements. This chapter explores advanced motion planning techniques that enable robots to execute complex movements in dynamic environments while maintaining stability, efficiency, and safety.

Unlike digital systems where motion is abstract, Physical AI systems must consider:
- **Robot dynamics**: Mass, inertia, and physical constraints
- **Environmental constraints**: Obstacles, surfaces, and physical limitations
- **Real-time requirements**: Control loops operating at high frequencies
- **Safety considerations**: Collision avoidance and stable movement
- **Energy efficiency**: Optimal use of actuator power and battery life
- **Robustness**: Handling of disturbances and model uncertainties

Motion planning for Physical AI encompasses several key components:
- **Trajectory optimization**: Finding optimal paths considering robot dynamics
- **Model predictive control**: Real-time control with prediction and optimization
- **Dynamic obstacle avoidance**: Adjusting motion in response to moving obstacles
- **Whole-body control**: Coordinating all robot joints and actuators
- **Stability maintenance**: Keeping the robot stable during complex motions

## Trajectory Optimization Fundamentals

### Mathematical Foundations

Trajectory optimization is the process of finding an optimal path through state space that minimizes a cost function while satisfying constraints:

```
min ∫[t₀ to t_f] L(x(t), u(t), t) dt + φ(x(t_f))
subject to:
  ẋ(t) = f(x(t), u(t), t)  (dynamics constraints)
  g(x(t), u(t)) ≤ 0        (inequality constraints)
  h(x(t), u(t)) = 0        (equality constraints)
  x(t₀) = x₀               (initial conditions)
  x(t_f) in X_f            (final conditions)
```

Where:
- `x(t)` is the state vector (position, velocity, orientation, etc.)
- `u(t)` is the control input vector (forces, torques, joint velocities)
- `L` is the running cost function
- `φ` is the terminal cost function
- `f` represents the system dynamics
- `g` and `h` are constraint functions

### Basic Trajectory Optimization Implementation

```python
import numpy as np
import scipy.optimize as opt
from scipy.integrate import solve_ivp
import matplotlib.pyplot as plt

class TrajectoryOptimizer:
    """Basic trajectory optimizer for robotic systems"""

    def __init__(self, robot_model, dt=0.1, horizon=5.0):
        self.robot_model = robot_model
        self.dt = dt
        self.horizon = horizon
        self.num_steps = int(horizon / dt)

    def optimize_trajectory(self, start_state, goal_state, obstacles=None,
                          initial_guess=None):
        """
        Optimize trajectory from start_state to goal_state
        Args:
            start_state: Initial state vector [position, velocity, etc.]
            goal_state: Goal state vector
            obstacles: List of obstacles with positions and radii
            initial_guess: Initial trajectory guess (optional)
        Returns:
            Optimized trajectory as list of states and controls
        """
        # Define the optimization problem
        def objective(controls_flat):
            """Objective function to minimize"""
            states, controls = self.reshape_controls(controls_flat)
            return self.compute_trajectory_cost(states, controls, goal_state, obstacles)

        def dynamics_constraint(controls_flat):
            """Constraint enforcing dynamics"""
            states, controls = self.reshape_controls(controls_flat)
            return self.enforce_dynamics(states, controls)

        # Reshape controls from flat array to trajectory format
        n_controls = len(self.robot_model.control_limits)
        if initial_guess is None:
            initial_controls = np.zeros(self.num_steps * n_controls)
        else:
            initial_controls = initial_guess.flatten()

        # Define bounds for control inputs
        control_bounds = []
        for _ in range(self.num_steps):
            for i in range(n_controls):
                control_bounds.append((self.robot_model.control_limits[i][0],
                                     self.robot_model.control_limits[i][1]))

        # Optimization constraints
        constraints = {
            'type': 'eq',
            'fun': dynamics_constraint
        }

        # Run optimization
        result = opt.minimize(
            objective,
            initial_controls,
            method='SLSQP',
            bounds=control_bounds,
            constraints=constraints,
            options={'maxiter': 1000, 'disp': False}
        )

        if result.success:
            optimized_states, optimized_controls = self.reshape_controls(result.x)
            return optimized_states, optimized_controls
        else:
            raise RuntimeError(f"Trajectory optimization failed: {result.message}")

    def reshape_controls(self, controls_flat):
        """Reshape flattened controls to states and controls arrays"""
        n_controls = len(self.robot_model.control_limits)
        controls = controls_flat.reshape((self.num_steps, n_controls))

        # Simulate forward to get states
        states = np.zeros((self.num_steps + 1, len(self.robot_model.state_limits)))
        states[0] = self.start_state  # This would need to be passed in

        for i in range(self.num_steps):
            # Integrate dynamics
            k1 = self.robot_model.dynamics(states[i], controls[i])
            k2 = self.robot_model.dynamics(states[i] + self.dt/2 * k1, controls[i])
            k3 = self.robot_model.dynamics(states[i] + self.dt/2 * k2, controls[i])
            k4 = self.robot_model.dynamics(states[i] + self.dt * k3, controls[i])

            states[i+1] = states[i] + self.dt/6 * (k1 + 2*k2 + 2*k3 + k4)

        return states, controls

    def compute_trajectory_cost(self, states, controls, goal_state, obstacles):
        """Compute total trajectory cost"""
        total_cost = 0.0

        # Goal reaching cost
        goal_cost = np.sum((states[-1] - goal_state)**2)
        total_cost += 1000 * goal_cost  # High weight for goal achievement

        # State regularization (smoothness)
        for i in range(len(states) - 1):
            # Velocity cost
            vel_cost = np.sum(states[i, self.robot_model.vel_indices]**2)
            total_cost += 0.1 * vel_cost

            # Acceleration cost
            if i > 0:
                acc_cost = np.sum((states[i] - states[i-1])**2)
                total_cost += 0.05 * acc_cost

        # Control effort cost
        for i in range(len(controls)):
            ctrl_cost = np.sum(controls[i]**2)
            total_cost += 0.01 * ctrl_cost

        # Obstacle avoidance cost
        if obstacles is not None:
            for state in states:
                for obs in obstacles:
                    dist = np.linalg.norm(state[:2] - obs['position'][:2])  # Assuming 2D position in first 2 elements
                    if dist < obs['radius'] + 0.5:  # 0.5m safety margin
                        obs_cost = 1000 * max(0, obs['radius'] + 0.5 - dist)**2
                        total_cost += obs_cost

        return total_cost

    def enforce_dynamics(self, states, controls):
        """Enforce dynamics constraints"""
        residuals = []

        for i in range(len(controls)):
            # Compute dynamics residual: ẋ - f(x, u) = 0
            actual_derivative = (states[i+1] - states[i]) / self.dt
            predicted_derivative = self.robot_model.dynamics(states[i], controls[i])
            residual = actual_derivative - predicted_derivative
            residuals.extend(residual)

        return np.array(residuals)

class SimpleRobotModel:
    """Simple robot model for trajectory optimization"""

    def __init__(self):
        # State: [x, y, theta, vx, vy, omega]
        # Control: [ax, ay, alpha] (linear acceleration, angular acceleration)
        self.state_dim = 6
        self.control_dim = 3

        # State indices
        self.pos_indices = [0, 1]      # x, y position
        self.orient_idx = 2            # theta orientation
        self.vel_indices = [3, 4]      # vx, vy velocity
        self.ang_vel_idx = 5           # omega angular velocity

        # Limits
        self.state_limits = [
            (-10, 10),    # x
            (-10, 10),    # y
            (-np.pi, np.pi),  # theta
            (-2, 2),      # vx
            (-2, 2),      # vy
            (-1, 1)       # omega
        ]

        self.control_limits = [
            (-1, 1),      # ax
            (-1, 1),      # ay
            (-0.5, 0.5)   # alpha
        ]

        # Robot parameters
        self.mass = 1.0
        self.inertia = 0.1

    def dynamics(self, state, control):
        """Robot dynamics: ẋ = f(x, u)"""
        x_dot = np.zeros_like(state)

        # Position derivatives
        x_dot[0] = state[3]  # ẋ = vx
        x_dot[1] = state[4]  # ẏ = vy
        x_dot[2] = state[5]  # θ̇ = ω

        # Velocity derivatives (acceleration)
        x_dot[3] = control[0]  # v̇x = ax
        x_dot[4] = control[1]  # v̇y = ay
        x_dot[5] = control[2]  # ω̇ = α

        return x_dot
```

### Model Predictive Control (MPC)

MPC is particularly effective for Physical AI systems as it handles constraints naturally and provides robust control:

```python
class ModelPredictiveController:
    """Model Predictive Controller for robotic motion planning"""

    def __init__(self, robot_model, horizon=10, dt=0.1):
        self.robot_model = robot_model
        self.horizon = horizon
        self.dt = dt
        self.n_states = robot_model.state_dim
        self.n_controls = robot_model.control_dim

        # MPC weights
        self.Q = np.eye(self.n_states) * 1.0    # State cost weights
        self.R = np.eye(self.n_controls) * 0.1  # Control cost weights
        self.Qf = np.eye(self.n_states) * 100   # Terminal state cost weights

    def compute_control(self, current_state, reference_trajectory,
                       obstacles=None, constraints=None):
        """
        Compute optimal control using MPC
        Args:
            current_state: Current robot state
            reference_trajectory: Desired trajectory to track
            obstacles: List of obstacles for collision avoidance
            constraints: Additional constraints (workspace, joint limits, etc.)
        Returns:
            Optimal control input
        """
        # Define optimization variables
        # States: [x_0, x_1, ..., x_N]
        # Controls: [u_0, u_1, ..., u_{N-1}]

        n_vars = (self.horizon + 1) * self.n_states + self.horizon * self.n_controls

        def mpc_objective(vars_flat):
            """MPC objective function"""
            states, controls = self.unpack_variables(vars_flat)

            total_cost = 0.0

            # Running costs
            for k in range(self.horizon):
                state_error = states[k] - reference_trajectory[k]
                control_effort = controls[k]

                total_cost += state_error.T @ self.Q @ state_error
                total_cost += control_effort.T @ self.R @ control_effort

                # Obstacle avoidance cost
                if obstacles:
                    total_cost += self.obstacle_cost(states[k], obstacles)

            # Terminal cost
            terminal_error = states[self.horizon] - reference_trajectory[self.horizon]
            total_cost += terminal_error.T @ self.Qf @ terminal_error

            return total_cost

        def mpc_constraints(vars_flat):
            """MPC constraints (dynamics and bounds)"""
            states, controls = self.unpack_variables(vars_flat)
            constraint_vals = []

            # Dynamics constraints: x_{k+1} = f(x_k, u_k)
            for k in range(self.horizon):
                next_state_pred = self.predict_next_state(states[k], controls[k])
                constraint_vals.extend((states[k+1] - next_state_pred).tolist())

            # Initial state constraint
            constraint_vals.extend((states[0] - current_state).tolist())

            # Control constraints
            for k in range(self.horizon):
                for i in range(self.n_controls):
                    min_ctrl, max_ctrl = self.robot_model.control_limits[i]
                    constraint_vals.append(controls[k, i] - min_ctrl)  # >= 0
                    constraint_vals.append(max_ctrl - controls[k, i])  # >= 0

            # State constraints
            for k in range(self.horizon + 1):
                for i in range(self.n_states):
                    min_state, max_state = self.robot_model.state_limits[i]
                    constraint_vals.append(states[k, i] - min_state)  # >= 0
                    constraint_vals.append(max_state - states[k, i])  # >= 0

            return np.array(constraint_vals)

        # Initial guess: zero controls
        initial_vars = np.zeros(n_vars)
        initial_states = np.tile(current_state, (self.horizon + 1, 1))
        initial_controls = np.zeros((self.horizon, self.n_controls))

        # Pack initial guess
        initial_vars[self.n_states:(self.horizon + 1) * self.n_states] = initial_states[1:].flatten()
        initial_vars[(self.horizon + 1) * self.n_states:] = initial_controls.flatten()

        # Solve MPC problem
        result = opt.minimize(
            mpc_objective,
            initial_vars,
            method='SLSQP',
            constraints={'type': 'eq', 'fun': mpc_constraints},
            options={'maxiter': 500, 'disp': False}
        )

        if result.success:
            _, optimized_controls = self.unpack_variables(result.x)
            return optimized_controls[0]  # Return first control input
        else:
            # Return safe control if optimization fails
            return np.zeros(self.n_controls)

    def unpack_variables(self, vars_flat):
        """Unpack flattened variables into states and controls"""
        states = np.zeros((self.horizon + 1, self.n_states))
        controls = np.zeros((self.horizon, self.n_controls))

        state_vars = vars_flat[:self.horizon * self.n_states]
        control_vars = vars_flat[self.horizon * self.n_states:]

        states[1:] = state_vars.reshape((self.horizon, self.n_states))
        controls = control_vars.reshape((self.horizon, self.n_controls))

        return states, controls

    def predict_next_state(self, current_state, control_input):
        """Predict next state using robot dynamics"""
        # Use Euler integration for prediction
        derivative = self.robot_model.dynamics(current_state, control_input)
        next_state = current_state + self.dt * derivative
        return next_state

    def obstacle_cost(self, state, obstacles):
        """Compute cost for obstacle avoidance"""
        total_cost = 0.0

        robot_pos = state[:2]  # Assuming position is in first 2 elements

        for obs in obstacles:
            dist = np.linalg.norm(robot_pos - obs['position'][:2])
            if dist < obs['radius'] + 0.5:  # Safety margin
                cost = 1000 * max(0, (obs['radius'] + 0.5 - dist))**2
                total_cost += cost

        return total_cost

# Example usage
robot_model = SimpleRobotModel()
mpc = ModelPredictiveController(robot_model, horizon=10, dt=0.1)

# Current state and reference trajectory
current_state = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])
reference_trajectory = np.zeros((11, 6))  # 10 steps + initial
for i in range(11):
    reference_trajectory[i] = [i*0.1, i*0.05, 0.0, 0.1, 0.05, 0.0]  # Simple trajectory

# Obstacles
obstacles = [{'position': [2.0, 1.0, 0], 'radius': 0.3}]

# Compute control
control_input = mpc.compute_control(current_state, reference_trajectory, obstacles)
print(f"MPC Control Output: {control_input}")
```

### Sampling-Based Motion Planning

For high-dimensional configuration spaces, sampling-based methods like RRT* are more effective:

```python
class RRTStarMotionPlanner:
    """RRT* motion planner for high-dimensional spaces"""

    def __init__(self, workspace_bounds, robot_radius=0.3, step_size=0.1):
        self.bounds = workspace_bounds  # [(min_x, max_x), (min_y, max_y), ...]
        self.robot_radius = robot_radius
        self.step_size = step_size
        self.dimension = len(workspace_bounds)
        self.nodes = []
        self.edges = {}  # adjacency list: {node_id: [neighbor_ids]}
        self.root_id = None

    def plan_motion(self, start_config, goal_config, obstacles, max_iterations=10000):
        """
        Plan motion using RRT* algorithm
        Args:
            start_config: Start configuration (numpy array)
            goal_config: Goal configuration (numpy array)
            obstacles: List of obstacles with collision checking
            max_iterations: Maximum number of RRT* iterations
        Returns:
            List of configurations forming the path, or None if no path found
        """
        # Initialize tree with start node
        start_node = RRTNode(config=start_config, parent=None, cost=0.0)
        self.root_id = 0
        self.nodes = [start_node]
        self.edges = {0: []}

        goal_bias = 0.05  # 5% chance to sample goal
        goal_tolerance = 0.1  # Distance tolerance for reaching goal

        for iteration in range(max_iterations):
            # Sample random configuration (with bias toward goal)
            if np.random.random() < goal_bias:
                rand_config = goal_config
            else:
                rand_config = self.sample_free_configuration(obstacles)

            # Find nearest node in tree
            nearest_id = self.find_nearest_node(rand_config)

            # Steer toward random configuration
            new_config = self.steer(self.nodes[nearest_id].config, rand_config)

            # Check if new configuration is collision-free
            if self.is_collision_free(self.nodes[nearest_id].config, new_config, obstacles):
                # Find best parent within radius
                best_parent_id, min_cost = self.find_best_parent(new_config, obstacles)

                if best_parent_id is not None:
                    # Add new node to tree
                    new_node = RRTNode(config=new_config, parent=best_parent_id, cost=min_cost)
                    new_id = len(self.nodes)
                    self.nodes.append(new_node)

                    # Update parent's children
                    self.nodes[best_parent_id].children.append(new_id)
                    self.edges[best_parent_id].append(new_id)
                    self.edges[new_id] = []

                    # Rewire tree to improve path costs
                    self.rewire_node(new_id, obstacles)

                    # Check if we've reached the goal
                    if np.linalg.norm(new_config - goal_config) < goal_tolerance:
                        # Construct path from goal to start
                        return self.extract_path(new_id)

        return None  # No path found

    def sample_free_configuration(self, obstacles):
        """Sample a configuration that's free of obstacles"""
        max_attempts = 100

        for _ in range(max_attempts):
            config = []
            for bound in self.bounds:
                val = np.random.uniform(bound[0], bound[1])
                config.append(val)

            config = np.array(config)

            if self.is_configuration_free(config, obstacles):
                return config

        # If we can't find a free configuration, return a random one within bounds
        config = []
        for bound in self.bounds:
            val = np.random.uniform(bound[0], bound[1])
            config.append(val)
        return np.array(config)

    def is_configuration_free(self, config, obstacles):
        """Check if configuration is collision-free"""
        for obstacle in obstacles:
            if self.check_collision(config, obstacle):
                return False
        return True

    def is_collision_free(self, config1, config2, obstacles):
        """Check if path between configurations is collision-free"""
        # Sample intermediate points along the path
        steps = int(np.linalg.norm(config2 - config1) / self.robot_radius)
        steps = max(10, steps)  # Minimum number of steps for safety

        for i in range(1, steps):
            t = i / steps
            intermediate = (1 - t) * config1 + t * config2

            if not self.is_configuration_free(intermediate, obstacles):
                return False

        return True

    def check_collision(self, config, obstacle):
        """Check collision between configuration and obstacle"""
        if hasattr(obstacle, 'contains_point'):
            return obstacle.contains_point(config, self.robot_radius)
        else:
            # Assume obstacle has 'position' and 'radius' attributes
            dist = np.linalg.norm(config[:2] - obstacle['position'][:2])  # 2D distance
            return dist < obstacle['radius'] + self.robot_radius

    def find_nearest_node(self, config):
        """Find nearest node in tree to given configuration"""
        min_dist = float('inf')
        nearest_id = 0

        for i, node in enumerate(self.nodes):
            dist = np.linalg.norm(config - node.config)
            if dist < min_dist:
                min_dist = dist
                nearest_id = i

        return nearest_id

    def steer(self, start_config, target_config):
        """Steer from start toward target by step size"""
        direction = target_config - start_config
        distance = np.linalg.norm(direction)

        if distance <= self.step_size:
            return target_config

        # Normalize direction and move by step size
        normalized_dir = direction / distance
        new_config = start_config + normalized_dir * self.step_size

        return new_config

    def find_best_parent(self, new_config, obstacles):
        """Find parent that gives minimum cost to reach new_config"""
        # Find all nodes within rewire radius
        radius = self.calculate_rewire_radius()
        neighbors = self.find_nodes_in_radius(new_config, radius)

        best_parent_id = None
        min_cost = float('inf')

        for neighbor_id in neighbors:
            neighbor_node = self.nodes[neighbor_id]
            edge_cost = np.linalg.norm(new_config - neighbor_node.config)

            if self.is_collision_free(neighbor_node.config, new_config, obstacles):
                potential_cost = neighbor_node.cost + edge_cost
                if potential_cost < min_cost:
                    min_cost = potential_cost
                    best_parent_id = neighbor_id

        return best_parent_id, min_cost

    def find_nodes_in_radius(self, config, radius):
        """Find all nodes within given radius"""
        neighbors = []

        for i, node in enumerate(self.nodes):
            if np.linalg.norm(config - node.config) <= radius:
                neighbors.append(i)

        return neighbors

    def calculate_rewire_radius(self):
        """Calculate rewire radius based on number of nodes"""
        # Standard RRT* rewire radius calculation
        gamma = 2 * (1 + 1/self.dimension)**(1/self.dimension)
        volume = 1  # Assuming unit hypercube
        for bound in self.bounds:
            volume *= (bound[1] - bound[0])

        radius = gamma * (np.log(len(self.nodes)) / len(self.nodes))**(1/self.dimension)
        return min(radius, 2.0)  # Cap radius for practical purposes

    def rewire_node(self, new_id, obstacles):
        """Rewire tree to improve path costs"""
        new_node = self.nodes[new_id]
        radius = self.calculate_rewire_radius()
        neighbors = self.find_nodes_in_radius(new_node.config, radius)

        for neighbor_id in neighbors:
            if neighbor_id == new_id:
                continue

            neighbor_node = self.nodes[neighbor_id]
            edge_cost = np.linalg.norm(new_node.config - neighbor_node.config)

            if self.is_collision_free(neighbor_node.config, new_node.config, obstacles):
                potential_cost = new_node.cost + edge_cost

                if potential_cost < neighbor_node.cost:
                    # Change parent of neighbor
                    old_parent = neighbor_node.parent
                    if old_parent is not None:
                        # Remove from old parent's children
                        if neighbor_id in self.nodes[old_parent].children:
                            self.nodes[old_parent].children.remove(neighbor_id)
                        if neighbor_id in self.edges[old_parent]:
                            self.edges[old_parent].remove(neighbor_id)

                    # Set new parent
                    neighbor_node.parent = new_id
                    neighbor_node.cost = potential_cost

                    # Update tree structure
                    self.nodes[new_id].children.append(neighbor_id)
                    self.edges[new_id].append(neighbor_id)

    def extract_path(self, goal_node_id):
        """Extract path from goal node back to root"""
        path = []
        current_id = goal_node_id

        while current_id is not None:
            path.append(self.nodes[current_id].config.copy())
            current_id = self.nodes[current_id].parent

        path.reverse()
        return path

class RRTNode:
    """Node in RRT tree"""
    def __init__(self, config, parent, cost):
        self.config = config
        self.parent = parent
        self.cost = cost
        self.children = []
```

## Advanced Motion Planning Techniques

### Kinodynamic Planning

For systems where kinematic and dynamic constraints must be considered together:

```python
class KinodynamicPlanner:
    """Motion planning considering both kinematic and dynamic constraints"""

    def __init__(self, robot_model, integration_dt=0.01):
        self.robot_model = robot_model
        self.integration_dt = integration_dt
        self.nodes = []
        self.edges = {}

    def plan_with_dynamics(self, start_state, goal_state, obstacles,
                          max_iterations=5000, goal_tolerance=0.1):
        """
        Plan motion considering robot dynamics
        Args:
            start_state: Start state [position, velocity, acceleration, etc.]
            goal_state: Goal state
            obstacles: List of obstacles
            max_iterations: Maximum planning iterations
            goal_tolerance: Distance tolerance for goal
        Returns:
            Trajectory of states and controls, or None if no path found
        """
        # Initialize tree
        start_node = KinodynamicNode(
            state=start_state,
            control=np.zeros(self.robot_model.control_dim),
            parent=None,
            cost=0.0,
            time=0.0
        )

        self.nodes = [start_node]
        self.edges = {0: []}

        for iteration in range(max_iterations):
            # Sample random state (or bias toward goal)
            if np.random.random() < 0.05:  # 5% goal bias
                random_state = goal_state
            else:
                random_state = self.sample_random_state()

            # Find nearest node in tree
            nearest_id = self.find_nearest_state_node(random_state)

            # Generate control input to move toward random state
            control = self.generate_control_to_state(
                self.nodes[nearest_id].state, random_state
            )

            # Simulate forward using dynamics
            new_state, trajectory_segment = self.simulate_forward(
                self.nodes[nearest_id].state, control, obstacles
            )

            if new_state is not None:  # If trajectory is valid
                # Calculate cost (including time and control effort)
                trajectory_cost = self.calculate_trajectory_cost(
                    trajectory_segment, control, self.nodes[nearest_id].cost
                )

                # Create new node
                new_node = KinodynamicNode(
                    state=new_state,
                    control=control,
                    parent=nearest_id,
                    cost=trajectory_cost,
                    time=self.nodes[nearest_id].time + len(trajectory_segment) * self.integration_dt
                )

                new_id = len(self.nodes)
                self.nodes.append(new_node)

                # Update parent-child relationship
                self.nodes[nearest_id].children.append(new_id)
                self.edges[nearest_id].append(new_id)
                self.edges[new_id] = []

                # Check if goal is reached
                if self.state_distance(new_state, goal_state) < goal_tolerance:
                    return self.extract_trajectory(new_id)

        return None  # No path found

    def simulate_forward(self, initial_state, control_input, obstacles,
                        simulation_time=1.0):
        """
        Simulate robot dynamics forward in time
        Returns new state and trajectory segment if valid, None if collision
        """
        trajectory = [initial_state.copy()]
        current_state = initial_state.copy()

        num_steps = int(simulation_time / self.integration_dt)

        for step in range(num_steps):
            # Compute state derivative using dynamics model
            state_derivative = self.robot_model.dynamics(current_state, control_input)

            # Integrate using RK4 method for better accuracy
            k1 = self.integration_dt * state_derivative
            k2 = self.integration_dt * self.robot_model.dynamics(
                current_state + k1/2, control_input
            )
            k3 = self.integration_dt * self.robot_model.dynamics(
                current_state + k2/2, control_input
            )
            k4 = self.integration_dt * self.robot_model.dynamics(
                current_state + k3, control_input
            )

            next_state = current_state + (k1 + 2*k2 + 2*k3 + k4) / 6
            trajectory.append(next_state.copy())

            # Check for collision at this state
            if self.is_state_in_collision(next_state, obstacles):
                return None, None  # Collision detected

            current_state = next_state

        return current_state, trajectory

    def generate_control_to_state(self, current_state, target_state):
        """Generate control input to move toward target state"""
        # Simple proportional controller (can be replaced with more sophisticated methods)
        state_error = target_state - current_state

        # Apply control limits
        control = np.clip(state_error * 0.1,  # Simple proportional gain
                         self.robot_model.control_limits[:, 0],
                         self.robot_model.control_limits[:, 1])

        return control

    def is_state_in_collision(self, state, obstacles):
        """Check if state is in collision with any obstacles"""
        robot_pos = state[:2]  # Assuming position is in first 2 elements

        for obstacle in obstacles:
            if hasattr(obstacle, 'contains_point'):
                if obstacle.contains_point(robot_pos, self.robot_model.safety_radius):
                    return True
            else:
                # Calculate distance to obstacle
                obs_pos = obstacle['position'][:2]  # 2D position
                dist = np.linalg.norm(robot_pos - obs_pos)
                if dist < obstacle['radius'] + self.robot_model.safety_radius:
                    return True

        return False

    def calculate_trajectory_cost(self, trajectory_segment, control, parent_cost):
        """Calculate cost of trajectory segment"""
        # Cost components:
        # 1. Time cost
        time_cost = len(trajectory_segment) * self.integration_dt

        # 2. Control effort cost
        control_cost = np.sum(control**2)

        # 3. Path length cost
        path_cost = 0.0
        for i in range(1, len(trajectory_segment)):
            path_cost += np.linalg.norm(
                trajectory_segment[i][:2] - trajectory_segment[i-1][:2]  # Position difference
            )

        return parent_cost + time_cost + 0.1 * control_cost + 0.5 * path_cost

    def find_nearest_state_node(self, target_state):
        """Find node with state closest to target state"""
        min_dist = float('inf')
        nearest_id = 0

        for i, node in enumerate(self.nodes):
            dist = self.state_distance(node.state, target_state)
            if dist < min_dist:
                min_dist = dist
                nearest_id = i

        return nearest_id

    def state_distance(self, state1, state2):
        """Calculate distance between states (can weight different components)"""
        # Simple Euclidean distance (could be weighted differently)
        return np.linalg.norm(state1 - state2)

    def extract_trajectory(self, goal_node_id):
        """Extract complete trajectory from goal back to start"""
        trajectory = []
        controls = []
        current_id = goal_node_id

        while current_id is not None:
            node = self.nodes[current_id]
            trajectory.append(node.state.copy())
            controls.append(node.control.copy())
            current_id = node.parent

        trajectory.reverse()
        controls.reverse()

        return trajectory, controls

class KinodynamicNode:
    """Node for kinodynamic planning"""
    def __init__(self, state, control, parent, cost, time):
        self.state = state
        self.control = control
        self.parent = parent
        self.cost = cost
        self.time = time
        self.children = []
```

### Optimization-Based Motion Planning

Using optimization techniques for trajectory generation:

```python
from scipy.optimize import minimize
import casadi as ca

class OptimizationBasedPlanner:
    """Motion planning using optimization techniques"""

    def __init__(self, robot_model, horizon=20, dt=0.05):
        self.robot_model = robot_model
        self.horizon = horizon
        self.dt = dt
        self.n_states = robot_model.state_dim
        self.n_controls = robot_model.control_dim

    def plan_trajectory_optimization(self, start_state, goal_state, obstacles,
                                   constraints=None, weights=None):
        """
        Plan trajectory using direct collocation optimization
        """
        # Define optimization variables
        X = ca.MX.sym('X', self.n_states, self.horizon + 1)  # State trajectory
        U = ca.MX.sym('U', self.n_controls, self.horizon)   # Control trajectory

        # Define cost function
        cost = 0

        # Goal reaching cost
        goal_cost = ca.mtimes((X[:, -1] - goal_state).T, (X[:, -1] - goal_state))
        cost += 1000 * goal_cost

        # Running costs
        for k in range(self.horizon):
            # State deviation from reference (if provided)
            # For now, just penalize velocity deviations from desired
            vel_cost = ca.mtimes(X[3:5, k].T, X[3:5, k])  # Penalize high velocities
            ctrl_cost = ca.mtimes(U[:, k].T, U[:, k])     # Penalize control effort
            cost += 0.1 * vel_cost + 0.01 * ctrl_cost

        # Obstacle avoidance costs
        for k in range(self.horizon + 1):
            for obs in obstacles:
                pos = X[0:2, k]  # Position is first 2 elements
                obs_pos = ca.vertcat(obs['position'][0], obs['position'][1])
                dist = ca.norm_2(pos - obs_pos)
                obs_radius = obs['radius'] + self.robot_model.safety_radius
                # Soft constraint using exponential penalty
                obs_cost = 1000 * ca.exp(-5 * (dist - obs_radius))
                cost += obs_cost

        # Define constraints
        constraints_eq = []
        constraints_ub = []
        constraints_lb = []

        # Dynamics constraints using collocation
        for k in range(self.horizon):
            x_k = X[:, k]
            u_k = U[:, k]
            x_k_plus_1 = X[:, k + 1]

            # Use RK4 integration for dynamics
            k1 = self.robot_model.casadi_dynamics(x_k, u_k)
            k2 = self.robot_model.casadi_dynamics(x_k + self.dt/2 * k1, u_k)
            k3 = self.robot_model.casadi_dynamics(x_k + self.dt/2 * k2, u_k)
            k4 = self.robot_model.casadi_dynamics(x_k + self.dt * k3, u_k)

            x_next = x_k + self.dt/6 * (k1 + 2*k2 + 2*k3 + k4)
            constraints_eq.extend((x_k_plus_1 - x_next).elements())
            constraints_ub.extend([0] * self.n_states)
            constraints_lb.extend([0] * self.n_states)

        # Initial state constraint
        constraints_eq.extend((X[:, 0] - start_state).elements())
        constraints_ub.extend([0] * self.n_states)
        constraints_lb.extend([0] * self.n_states)

        # Control bounds
        for k in range(self.horizon):
            for i in range(self.n_controls):
                constraints_ub.append(self.robot_model.control_limits[i][1])
                constraints_lb.append(self.robot_model.control_limits[i][0])
                constraints_eq.append(U[i, k])

        # State bounds
        for k in range(self.horizon + 1):
            for i in range(self.n_states):
                constraints_ub.append(self.robot_model.state_limits[i][1])
                constraints_lb.append(self.robot_model.state_limits[i][0])
                constraints_eq.append(X[i, k])

        # Create optimization problem
        opt_variables = ca.vertcat(X.reshape((-1, 1)), U.reshape((-1, 1)))
        constraints = ca.vertcat(*constraints_eq)

        nlp = {
            'x': opt_variables,
            'f': cost,
            'g': constraints
        }

        # Solve optimization problem
        solver = ca.nlpsol('solver', 'ipopt', nlp)

        # Initial guess
        x_init = np.tile(start_state, (self.horizon + 1, 1)).T
        u_init = np.zeros((self.n_controls, self.horizon))

        init_vars = ca.vertcat(x_init.reshape((-1, 1)), u_init.reshape((-1, 1)))

        # Bounds
        lbx = np.full(init_vars.shape[0], -ca.inf)
        ubx = np.full(init_vars.shape[0], ca.inf)

        # Solve
        try:
            sol = solver(x0=init_vars, lbx=lbx, ubx=ubx, lbg=constraints_lb, ubg=constraints_ub)

            # Extract solution
            solution = sol['x'].full().flatten()

            n_states_vars = (self.horizon + 1) * self.n_states
            state_traj = solution[:n_states_vars].reshape((self.n_states, self.horizon + 1))
            ctrl_traj = solution[n_states_vars:].reshape((self.n_controls, self.horizon))

            return state_traj.T, ctrl_traj.T

        except Exception as e:
            print(f"Optimization failed: {e}")
            return None, None

class CasadiRobotModel:
    """Robot model compatible with CasADi for optimization"""

    def __init__(self):
        self.state_dim = 6  # [x, y, theta, vx, vy, omega]
        self.control_dim = 3  # [ax, ay, alpha]
        self.safety_radius = 0.3

        # Define symbolic variables for CasADi
        self.x_sym = ca.MX.sym('x', self.state_dim)
        self.u_sym = ca.MX.sym('u', self.control_dim)

    def casadi_dynamics(self, state, control):
        """CasADi-compatible dynamics function"""
        x_dot = ca.MX.zeros(self.state_dim)

        # Position derivatives
        x_dot[0] = state[3]  # ẋ = vx
        x_dot[1] = state[4]  # ẏ = vy
        x_dot[2] = state[5]  # θ̇ = ω

        # Velocity derivatives
        x_dot[3] = control[0]  # v̇x = ax
        x_dot[4] = control[1]  # v̇y = ay
        x_dot[5] = control[2]  # ω̇ = α

        return x_dot

    @property
    def state_limits(self):
        return np.array([
            [-10, 10],    # x
            [-10, 10],    # y
            [-np.pi, np.pi],  # theta
            [-2, 2],      # vx
            [-2, 2],      # vy
            [-1, 1]       # omega
        ])

    @property
    def control_limits(self):
        return np.array([
            [-1, 1],      # ax
            [-1, 1],      # ay
            [-0.5, 0.5]   # alpha
        ])
```

## Real-Time Motion Planning

### Fast Marching Method for Real-Time Path Planning

For real-time applications where path planning needs to happen quickly:

```python
class FastMarchingPlanner:
    """Fast Marching Method for real-time path planning"""

    def __init__(self, grid_resolution=0.1, max_distance=float('inf')):
        self.grid_resolution = grid_resolution
        self.max_distance = max_distance

    def plan_path(self, grid, start, goal):
        """
        Plan path using Fast Marching Method
        Args:
            grid: 2D array where 0 = free space, 1 = obstacle
            start: Start position (row, col)
            goal: Goal position (row, col)
        Returns:
            Path as list of (row, col) positions
        """
        rows, cols = grid.shape

        # Initialize distance and state arrays
        distance = np.full((rows, cols), np.inf)
        state = np.zeros((rows, cols))  # 0 = far, 1 = trial, 2 = accepted

        # Set goal distance to 0
        distance[goal] = 0
        state[goal] = 2  # Accepted

        # Initialize trial points around goal
        trial_points = self.get_neighbors(goal, rows, cols)
        for pt in trial_points:
            if grid[pt] == 0:  # Free space
                distance[pt] = self.compute_distance(pt, goal, distance, grid)
                state[pt] = 1  # Trial

        # Fast marching loop
        while trial_points:
            # Find point with minimum distance
            min_dist = float('inf')
            current = None
            current_idx = -1

            for i, pt in enumerate(trial_points):
                if distance[pt] < min_dist:
                    min_dist = distance[pt]
                    current = pt
                    current_idx = i

            if current is None:
                break  # No more trial points

            # Remove current from trial points
            trial_points.pop(current_idx)
            state[current] = 2  # Accept current point

            # Check if we reached start
            if current == start:
                break

            # Add neighbors to trial points
            neighbors = self.get_neighbors(current, rows, cols)
            for neighbor in neighbors:
                if grid[neighbor] == 0 and state[neighbor] != 2:  # Free and not accepted
                    new_dist = self.compute_distance(neighbor, current, distance, grid)

                    if new_dist < distance[neighbor]:
                        distance[neighbor] = new_dist

                    if state[neighbor] == 0:  # Far
                        state[neighbor] = 1  # Move to trial
                        trial_points.append(neighbor)

        # Backtrack from start to goal
        path = self.backtrack_path(distance, start, goal, grid)
        return path

    def get_neighbors(self, pos, rows, cols):
        """Get 8-connected neighbors"""
        neighbors = []
        r, c = pos

        for dr in [-1, 0, 1]:
            for dc in [-1, 0, 1]:
                if dr == 0 and dc == 0:
                    continue

                nr, nc = r + dr, c + dc
                if 0 <= nr < rows and 0 <= nc < cols:
                    neighbors.append((nr, nc))

        return neighbors

    def compute_distance(self, pos, neighbor, distance, grid):
        """Compute distance using upwind finite difference"""
        r, c = pos

        # Check all possible neighbors to find minimum distance
        min_dist = float('inf')

        # Check horizontal/vertical neighbors
        for dr, dc in [(-1, 0), (1, 0), (0, -1), (0, 1)]:
            nr, nc = r + dr, c + dc
            if 0 <= nr < distance.shape[0] and 0 <= nc < distance.shape[1]:
                if distance[nr, nc] < min_dist:
                    min_dist = distance[nr, nc]

        # Check diagonal neighbors
        for dr, dc in [(-1, -1), (-1, 1), (1, -1), (1, 1)]:
            nr, nc = r + dr, c + dc
            if 0 <= nr < distance.shape[0] and 0 <= nc < distance.shape[1]:
                # Diagonal distance includes sqrt(2) factor
                diag_dist = distance[nr, nc] + np.sqrt(2) * self.grid_resolution
                if diag_dist < min_dist:
                    min_dist = diag_dist

        return min_dist + self.grid_resolution

    def backtrack_path(self, distance, start, goal, grid):
        """Backtrack from start to goal using distance field"""
        path = [start]
        current = start
        rows, cols = grid.shape

        while current != goal:
            # Find neighbor with minimum distance
            min_dist = float('inf')
            next_pos = None

            neighbors = self.get_neighbors(current, rows, cols)
            for neighbor in neighbors:
                if grid[neighbor] == 0 and distance[neighbor] < min_dist:
                    min_dist = distance[neighbor]
                    next_pos = neighbor

            if next_pos is None or next_pos == current:
                # No valid path found
                return None

            path.append(next_pos)
            current = next_pos

        return path

# Alternative implementation using Dijkstra's algorithm for comparison
class RealTimeDijkstraPlanner:
    """Dijkstra-based real-time planner with optimizations"""

    def __init__(self, grid_resolution=0.1):
        self.grid_resolution = grid_resolution
        self.directions = [
            (-1, -1), (-1, 0), (-1, 1),
            (0, -1),           (0, 1),
            (1, -1),  (1, 0),  (1, 1)
        ]
        self.costs = [
            np.sqrt(2), 1.0, np.sqrt(2),
            1.0,        1.0,
            np.sqrt(2), 1.0, np.sqrt(2)
        ]

    def plan_path(self, grid, start, goal):
        """Plan path using optimized Dijkstra's algorithm"""
        rows, cols = grid.shape

        # Use priority queue for efficient minimum extraction
        open_set = [(0, start)]
        came_from = {}
        g_score = {start: 0}
        count = 0  # Tie-breaking counter

        while open_set:
            current_g, current = heapq.heappop(open_set)

            if current == goal:
                return self.reconstruct_path(came_from, current)

            # Check neighbors
            for i, direction in enumerate(self.directions):
                neighbor = (current[0] + direction[0], current[1] + direction[1])

                # Check bounds
                if not (0 <= neighbor[0] < rows and 0 <= neighbor[1] < cols):
                    continue

                # Check if neighbor is traversable
                if grid[neighbor] == 1:  # Obstacle
                    continue

                tentative_g = g_score[current] + self.costs[i]

                if neighbor not in g_score or tentative_g < g_score[neighbor]:
                    came_from[neighbor] = current
                    g_score[neighbor] = tentative_g
                    f_score = tentative_g  # Dijkstra uses g_score only
                    count += 1
                    heapq.heappush(open_set, (f_score, neighbor))

        return None  # No path found

    def reconstruct_path(self, came_from, current):
        """Reconstruct path from came_from dictionary"""
        path = [current]
        while current in came_from:
            current = came_from[current]
            path.append(current)
        return path[::-1]
```

### Dynamic Window Approach (DWA) for Real-Time Navigation

DWA is excellent for local navigation with obstacle avoidance:

```python
class DynamicWindowApproach:
    """Dynamic Window Approach for real-time local navigation"""

    def __init__(self, robot_model, max_speed=1.0, max_yawrate=40.0,
                 max_accel=0.5, max_dyawrate=80.0, dt=0.1, predict_time=3.0):
        self.robot_model = robot_model
        self.max_speed = max_speed
        self.max_yawrate = max_yawrate
        self.max_accel = max_accel
        self.max_dyawrate = max_dyawrate
        self.dt = dt
        self.predict_time = predict_time

        # Cost weights
        self.to_goal_cost_gain = 0.15
        self.speed_cost_gain = 1.0
        self.obstacle_cost_gain = 1.0
        self.robot_radius = robot_model.safety_radius

    def plan_local_motion(self, current_state, goal, obstacles,
                         dynamic_obstacles=None):
        """
        Plan local motion using Dynamic Window Approach
        Args:
            current_state: Current robot state [x, y, theta, v, omega]
            goal: Goal position [x, y]
            obstacles: Static obstacles in environment
            dynamic_obstacles: Moving obstacles with velocity information
        Returns:
            Optimal velocity commands [v, omega]
        """
        # Generate dynamic window
        vs = self.get_dynamic_window(current_state)

        # Evaluate all possible trajectories in the window
        best_traj = None
        min_cost = float('inf')

        for v in np.arange(vs[0], vs[1], self.max_accel * self.dt):
            for omega in np.arange(vs[2], vs[3],
                                 self.max_dyawrate * np.pi / 180.0 * self.dt):

                # Simulate trajectory
                traj = self.predict_trajectory(current_state, v, omega)

                # Calculate costs
                to_goal_cost = self.calc_to_goal_cost(traj, goal)
                speed_cost = self.calc_speed_cost(v)
                ob_cost = self.calc_obstacle_cost(traj, obstacles, dynamic_obstacles)

                # Total cost
                final_cost = (self.to_goal_cost_gain * to_goal_cost +
                             self.speed_cost_gain * speed_cost +
                             self.obstacle_cost_gain * ob_cost)

                # Find best trajectory
                if final_cost < min_cost:
                    min_cost = final_cost
                    best_traj = [v, omega, traj]

        if best_traj is None:
            # No valid trajectory found, stop
            return 0.0, 0.0

        return best_traj[0], best_traj[1]

    def get_dynamic_window(self, state):
        """Calculate dynamic window based on robot constraints"""
        # Dynamic window = [v_min, v_max, omega_min, omega_max]
        vs = [0, self.max_speed,
              -np.deg2rad(self.max_yawrate), np.deg2rad(self.max_yawrate)]

        # Dynamic window considering current velocity and constraints
        vd = [state[3] - self.max_accel * self.dt,
              state[3] + self.max_accel * self.dt,
              state[4] - np.deg2rad(self.max_dyawrate) * self.dt,
              state[4] + np.deg2rad(self.max_dyawrate) * self.dt]

        # Calculate window by intersection of vs and vd
        dw = [max(vs[0], vd[0]), min(vs[1], vd[1]),
              max(vs[2], vd[2]), min(vs[3], vd[3])]

        return dw

    def predict_trajectory(self, state, v, omega):
        """Predict trajectory for given velocity commands"""
        state = np.array(state)
        trajectory = np.array([state])

        time = 0
        while time <= self.predict_time:
            state = self.motion(state, [v, omega])
            trajectory = np.vstack((trajectory,
                                   np.array([state[0], state[1], state[2], state[3], state[4]])))
            time += self.dt

        return trajectory

    def motion(self, state, velocity_commands):
        """Motion model for robot"""
        v, omega = velocity_commands
        dt = self.dt

        state[0] += v * np.cos(state[2]) * dt
        state[1] += v * np.sin(state[2]) * dt
        state[2] += omega * dt
        state[3] = v
        state[4] = omega

        return state

    def calc_to_goal_cost(self, traj, goal):
        """Calculate cost to goal based on trajectory"""
        dx = goal[0] - traj[-1, 0]
        dy = goal[1] - traj[-1, 1]
        error_angle = np.arctan2(dy, dx)
        cost_angle = error_angle - traj[-1, 2]
        cost = abs(np.arctan2(np.sin(cost_angle), np.cos(cost_angle)))

        return cost

    def calc_speed_cost(self, v):
        """Calculate speed cost (higher speeds are preferred)"""
        return self.max_speed - abs(v)

    def calc_obstacle_cost(self, traj, obstacles, dynamic_obstacles=None):
        """Calculate obstacle cost for trajectory"""
        min_dist = float('inf')

        for point in traj:
            for obs in obstacles:
                dist = np.sqrt((point[0] - obs['position'][0])**2 +
                              (point[1] - obs['position'][1])**2)
                dist -= obs['radius']  # Account for obstacle size
                dist -= self.robot_radius  # Account for robot size
                min_dist = min(min_dist, dist)

                if min_dist <= 0:  # Collision
                    return float('inf')

        # If dynamic obstacles provided, consider them too
        if dynamic_obstacles:
            for point in traj:
                for dyn_obs in dynamic_obstacles:
                    # Predict dynamic obstacle position at this time
                    time_idx = np.where((traj == point).all(axis=1))[0]
                    if len(time_idx) > 0:
                        time_step = time_idx[0] * self.dt
                        predicted_pos = (
                            dyn_obs['position'][0] + dyn_obs['velocity'][0] * time_step,
                            dyn_obs['position'][1] + dyn_obs['velocity'][1] * time_step
                        )

                        dist = np.sqrt((point[0] - predicted_pos[0])**2 +
                                      (point[1] - predicted_pos[1])**2)
                        dist -= dyn_obs['radius'] + self.robot_radius
                        min_dist = min(min_dist, dist)

        # Cost is inversely proportional to distance
        return 1.0 / min_dist if min_dist != float('inf') else float('inf')

# Example usage
def demonstrate_dwa():
    """Demonstrate Dynamic Window Approach"""
    robot_model = SimpleRobotModel()  # From earlier examples
    dwa = DynamicWindowApproach(robot_model)

    # Current state: [x, y, theta, v, omega]
    current_state = np.array([0.0, 0.0, 0.0, 0.0, 0.0])

    # Goal position
    goal = np.array([5.0, 5.0])

    # Obstacles
    obstacles = [
        {'position': [2.0, 2.0], 'radius': 0.3},
        {'position': [3.0, 4.0], 'radius': 0.2}
    ]

    # Dynamic obstacles (if any)
    dynamic_obstacles = [
        {'position': [1.0, 1.0], 'velocity': [0.1, 0.1], 'radius': 0.2}
    ]

    # Plan local motion
    v_cmd, omega_cmd = dwa.plan_local_motion(current_state, goal, obstacles, dynamic_obstacles)

    print(f"Recommended velocity: v={v_cmd:.3f}, omega={omega_cmd:.3f}")

    return v_cmd, omega_cmd
```

## Integration with Perception Systems

### SLAM-Integrated Planning

Planning with real-time localization and mapping:

```python
class SLAMIntegratedPlanner:
    """Motion planning integrated with SLAM for unknown environments"""

    def __init__(self, slam_system, local_planner, global_planner):
        self.slam = slam_system
        self.local_planner = local_planner
        self.global_planner = global_planner
        self.occupancy_grid = None
        self.local_map = None
        self.global_path = []
        self.path_following_controller = PathFollowingController()

    def plan_with_slam(self, robot_state, goal, sensor_data,
                      exploration_mode=False):
        """
        Plan motion while building map with SLAM
        Args:
            robot_state: Current robot state [x, y, theta, v, omega]
            goal: Goal position [x, y]
            sensor_data: Sensor measurements (e.g., laser scan, camera)
            exploration_mode: Whether to explore unknown areas
        Returns:
            Velocity commands [v, omega] or exploration commands
        """
        # Update SLAM with new sensor data
        self.slam.update(sensor_data, robot_state)

        # Get current maps
        self.occupancy_grid = self.slam.get_global_map()
        self.local_map = self.slam.get_local_map(robot_state)

        if exploration_mode:
            # For exploration, find frontier points
            goal = self.find_exploration_target(robot_state)

        # Plan global path to goal (if not in exploration mode)
        if not exploration_mode:
            self.global_path = self.global_planner.plan_path(
                self.occupancy_grid,
                robot_state[:2],
                goal
            )

        # Plan local motion considering immediate obstacles
        local_command = self.local_planner.plan_local_motion(
            robot_state,
            goal if not exploration_mode else self.estimate_frontier_direction(robot_state),
            self.get_local_obstacles(sensor_data)
        )

        return local_command

    def find_exploration_target(self, robot_state):
        """Find exploration target in unknown areas"""
        # Find frontiers (boundary between known free space and unknown)
        frontiers = self.find_frontiers(self.occupancy_grid)

        if frontiers:
            # Find closest frontier to robot
            closest_frontier = self.get_closest_frontier(robot_state[:2], frontiers)
            return closest_frontier
        else:
            # No frontiers found, explore in a general direction
            return self.explore_direction(robot_state)

    def find_frontiers(self, grid):
        """Find frontiers in occupancy grid"""
        frontiers = []
        rows, cols = grid.shape

        for i in range(1, rows - 1):
            for j in range(1, cols - 1):
                if grid[i, j] == 0.5:  # Unknown space
                    # Check if adjacent to known free space
                    adjacent_free = False
                    for di in [-1, 0, 1]:
                        for dj in [-1, 0, 1]:
                            if 0 <= i + di < rows and 0 <= j + dj < cols:
                                if grid[i + di, j + dj] == 0:  # Free space
                                    adjacent_free = True
                                    break
                        if adjacent_free:
                            break

                    if adjacent_free:
                        frontiers.append((i, j))

        return frontiers

    def get_closest_frontier(self, robot_pos, frontiers):
        """Get closest frontier to robot position"""
        if not frontiers:
            return None

        min_dist = float('inf')
        closest = None

        for frontier in frontiers:
            # Convert grid coordinates to world coordinates
            world_pos = self.grid_to_world(frontier)
            dist = np.linalg.norm(np.array(world_pos) - np.array(robot_pos))

            if dist < min_dist:
                min_dist = dist
                closest = world_pos

        return closest

    def grid_to_world(self, grid_pos):
        """Convert grid coordinates to world coordinates"""
        # This would depend on your grid resolution and origin
        resolution = 0.1  # Example resolution
        origin = (0, 0)   # Example origin
        world_x = grid_pos[0] * resolution + origin[0]
        world_y = grid_pos[1] * resolution + origin[1]
        return (world_x, world_y)

    def estimate_frontier_direction(self, robot_state):
        """Estimate direction for frontier exploration"""
        # For now, return a point in a general direction
        return (robot_state[0] + 5.0, robot_state[1])  # 5m ahead

    def get_local_obstacles(self, sensor_data):
        """Extract local obstacles from sensor data"""
        obstacles = []

        # Process laser scan data to identify obstacles
        if 'laser_scan' in sensor_data:
            scan_data = sensor_data['laser_scan']
            robot_pos = sensor_data.get('robot_position', [0, 0])

            for i, distance in enumerate(scan_data):
                if distance < 3.0:  # Consider obstacles within 3m
                    # Convert polar coordinates to Cartesian
                    angle = sensor_data.get('start_angle', 0) + i * sensor_data.get('angle_increment', 0.01)
                    x = robot_pos[0] + distance * np.cos(angle)
                    y = robot_pos[1] + distance * np.sin(angle)

                    obstacles.append({
                        'position': [x, y],
                        'radius': 0.1,  # Estimated obstacle size
                        'confidence': 0.9  # High confidence for close obstacles
                    })

        return obstacles

class PathFollowingController:
    """Controller for following planned paths"""

    def __init__(self, lookahead_distance=0.5, max_linear_speed=1.0,
                 angular_gain=2.0, linear_gain=1.0):
        self.lookahead_distance = lookahead_distance
        self.max_linear_speed = max_linear_speed
        self.angular_gain = angular_gain
        self.linear_gain = linear_gain

    def follow_path(self, robot_state, path, current_waypoint_idx=0):
        """
        Follow a path using pure pursuit algorithm
        Args:
            robot_state: Current robot state [x, y, theta, v, omega]
            path: Planned path as list of [x, y] positions
            current_waypoint_idx: Index of current closest waypoint
        Returns:
            Velocity commands [v, omega]
        """
        if not path or current_waypoint_idx >= len(path):
            return 0.0, 0.0  # Stop if no path or reached end

        # Find lookahead point on path
        lookahead_point = self.find_lookahead_point(robot_state, path, current_waypoint_idx)

        if lookahead_point is None:
            # No lookahead point found, continue with current direction
            return self.max_linear_speed, 0.0

        # Calculate control commands using pure pursuit
        v, omega = self.pure_pursuit_control(robot_state, lookahead_point)

        return v, omega

    def find_lookahead_point(self, robot_state, path, start_idx):
        """Find the point on path that is lookahead_distance away from robot"""
        robot_pos = robot_state[:2]

        for i in range(start_idx, len(path)):
            path_point = path[i][:2]  # Get x, y coordinates
            distance = np.linalg.norm(robot_pos - path_point)

            if distance >= self.lookahead_distance:
                return path_point

        # If no point is far enough, return the last point
        if path:
            return path[-1][:2]

        return None

    def pure_pursuit_control(self, robot_state, lookahead_point):
        """Pure pursuit path following control"""
        robot_pos = robot_state[:2]
        robot_theta = robot_state[2]

        # Calculate vector from robot to lookahead point
        dx = lookahead_point[0] - robot_pos[0]
        dy = lookahead_point[1] - robot_pos[1]

        # Calculate angle to target
        angle_to_target = np.arctan2(dy, dx)

        # Calculate angle error
        angle_error = angle_to_target - robot_theta
        # Normalize angle to [-π, π]
        angle_error = np.arctan2(np.sin(angle_error), np.cos(angle_error))

        # Calculate curvature (1/R where R is radius of turn)
        distance_to_target = np.sqrt(dx**2 + dy**2)
        if distance_to_target > 0:
            curvature = 2 * np.sin(angle_error) / distance_to_target
        else:
            curvature = 0

        # Calculate linear and angular velocities
        linear_vel = min(self.max_linear_speed,
                        self.linear_gain * np.cos(angle_error))
        angular_vel = self.angular_gain * curvature

        # Limit angular velocity
        angular_vel = max(-1.0, min(1.0, angular_vel))

        return max(0, linear_vel), angular_vel
```

## Multi-Robot Path Planning

### Decentralized Multi-Robot Planning

For coordinating multiple robots in the same environment:

```python
class MultiRobotPlanner:
    """Decentralized multi-robot path planning with collision avoidance"""

    def __init__(self, num_robots, robot_radius=0.3, communication_range=5.0):
        self.num_robots = num_robots
        self.robot_radius = robot_radius
        self.communication_range = communication_range
        self.robot_states = [None] * num_robots
        self.robot_goals = [None] * num_robots
        self.robot_paths = [None] * num_robots
        self.assigned_tasks = [None] * num_robots
        self.planners = [AStarPlanner() for _ in range(num_robots)]

    def update_robot_state(self, robot_id, state, goal):
        """Update state and goal for a specific robot"""
        self.robot_states[robot_id] = state
        self.robot_goals[robot_id] = goal

    def plan_multi_robot_paths(self, environment_grid, robot_starts, robot_goals):
        """Plan paths for multiple robots with collision avoidance"""
        paths = [None] * self.num_robots
        success_count = 0

        # Plan paths sequentially with conflict resolution
        for robot_id in range(self.num_robots):
            path = self.plan_single_robot_path(
                robot_id, environment_grid, robot_starts[robot_id], robot_goals[robot_id], paths
            )

            if path:
                paths[robot_id] = path
                success_count += 1
            else:
                print(f"Failed to find path for robot {robot_id}")

        # Optimize paths to reduce conflicts
        optimized_paths = self.resolve_conflicts(paths, robot_starts, robot_goals)

        return optimized_paths

    def plan_single_robot_path(self, robot_id, grid, start, goal, existing_paths):
        """Plan path for single robot considering existing paths"""
        # Create temporary grid with inflated obstacles for other robots
        temp_grid = grid.copy()

        # Inflate obstacles for other robots' paths
        if existing_paths:
            for other_id, other_path in enumerate(existing_paths):
                if other_path and other_id != robot_id:
                    self.inflate_path_for_robot(temp_grid, other_path, self.robot_radius)

        # Plan path on modified grid
        path = self.planners[robot_id].plan_path(temp_grid, start, goal)

        return path

    def inflate_path_for_robot(self, grid, path, robot_radius):
        """Inflate path area to prevent collisions with other robots"""
        grid_resolution = 0.1  # Assuming 0.1m resolution
        inflation_cells = int(robot_radius / grid_resolution)

        for point in path:
            row, col = point
            for i in range(-inflation_cells, inflation_cells + 1):
                for j in range(-inflation_cells, inflation_cells + 1):
                    if (0 <= row + i < grid.shape[0] and
                        0 <= col + j < grid.shape[1]):
                        # Calculate distance from center
                        dist = np.sqrt(i**2 + j**2) * grid_resolution
                        if dist <= robot_radius:
                            grid[row + i, col + j] = 1  # Mark as obstacle

    def resolve_conflicts(self, paths, starts, goals):
        """Resolve conflicts between planned paths"""
        # Use Conflict-Based Search (CBS) or similar approach
        resolved_paths = paths.copy()

        # Detect conflicts between paths
        conflicts = self.detect_conflicts(resolved_paths)

        if conflicts:
            # Resolve conflicts using prioritized planning
            resolved_paths = self.resolve_conflicts_priority_based(resolved_paths, conflicts)

        return resolved_paths

    def detect_conflicts(self, paths):
        """Detect conflicts between robot paths"""
        conflicts = []

        for i in range(len(paths)):
            for j in range(i + 1, len(paths)):
                if paths[i] and paths[j]:
                    conflict = self.find_path_conflict(paths[i], paths[j])
                    if conflict:
                        conflicts.append({
                            'robots': (i, j),
                            'time': conflict['time'],
                            'position': conflict['position']
                        })

        return conflicts

    def find_path_conflict(self, path1, path2):
        """Find first conflict between two paths"""
        max_len = max(len(path1), len(path2))

        for t in range(max_len):
            pos1 = path1[min(t, len(path1)-1)] if path1 else None
            pos2 = path2[min(t, len(path2)-1)] if path2 else None

            if pos1 and pos2:
                distance = np.sqrt((pos1[0] - pos2[0])**2 + (pos1[1] - pos2[1])**2)
                if distance < 2 * self.robot_radius:  # Too close
                    return {
                        'time': t,
                        'position': ((pos1[0] + pos2[0])/2, (pos1[1] + pos2[1])/2)
                    }

        return None

    def resolve_conflicts_priority_based(self, paths, conflicts):
        """Resolve conflicts using priority-based approach"""
        # Assign priorities to robots (simple approach: robot ID as priority)
        priorities = list(range(len(paths)))

        # Sort conflicts by time (earlier conflicts first)
        conflicts.sort(key=lambda x: x['time'])

        for conflict in conflicts:
            robot1, robot2 = conflict['robots']

            # Robot with higher priority (lower ID) keeps its path
            # Robot with lower priority replans
            if priorities[robot1] < priorities[robot2]:
                # Robot 2 replans avoiding robot 1's path at conflict time
                paths[robot2] = self.replan_with_avoidance(
                    paths[robot2], paths[robot1], conflict['time'], conflict['position']
                )
            else:
                # Robot 1 replans avoiding robot 2's path at conflict time
                paths[robot1] = self.replan_with_avoidance(
                    paths[robot1], paths[robot2], conflict['time'], conflict['position']
                )

        return paths

    def replan_with_avoidance(self, original_path, other_path, conflict_time, conflict_pos):
        """Replan path to avoid conflict with another robot"""
        # This is a simplified approach
        # In practice, you'd use more sophisticated methods like CBS or reservation tables

        # Create temporary obstacle at conflict location and time
        temp_grid = np.zeros_like(original_path)  # This would need to be based on actual grid
        # For now, just return original path - would implement proper conflict resolution

        return original_path

class ReservationTable:
    """Reservation table for multi-robot path planning"""

    def __init__(self, time_horizon=100, space_resolution=0.1):
        self.time_horizon = time_horizon
        self.space_resolution = space_resolution
        self.reservations = {}  # {(x, y, t): robot_id}

    def reserve(self, position, time, robot_id):
        """Reserve a space-time cell for a robot"""
        if time < self.time_horizon:
            key = (position[0], position[1], time)
            self.reservations[key] = robot_id

    def is_reserved(self, position, time):
        """Check if a space-time cell is reserved"""
        if time >= self.time_horizon:
            return False

        key = (position[0], position[1], time)
        return key in self.reservations

    def get_reserving_robot(self, position, time):
        """Get robot that reserved a space-time cell"""
        key = (position[0], position[1], time)
        return self.reservations.get(key)

    def clear_reservation(self, position, time):
        """Clear a reservation"""
        key = (position[0], position[1], time)
        if key in self.reservations:
            del self.reservations[key]
```

## Navigation in Dynamic Environments

### Dynamic Obstacle Handling

Handling moving obstacles in real-time:

```python
class DynamicObstacleNavigator:
    """Navigation system for environments with moving obstacles"""

    def __init__(self, prediction_horizon=5.0, safety_margin=0.5):
        self.prediction_horizon = prediction_horizon
        self.safety_margin = safety_margin
        self.obstacle_predictor = ObstaclePredictor()
        self.trajectory_optimizer = TrajectoryOptimizer()
        self.local_planner = DynamicWindowApproach(None)  # Will be configured later

    def navigate_with_dynamic_obstacles(self, robot_state, goal,
                                      static_obstacles, dynamic_obstacles):
        """
        Navigate in environment with both static and dynamic obstacles
        Args:
            robot_state: Current robot state [x, y, theta, v, omega]
            goal: Goal position [x, y]
            static_obstacles: List of static obstacles
            dynamic_obstacles: List of dynamic obstacles with motion information
        Returns:
            Velocity commands [v, omega]
        """
        # Predict future positions of dynamic obstacles
        predicted_obstacles = self.predict_dynamic_obstacles(
            dynamic_obstacles, self.prediction_horizon
        )

        # Plan local trajectory considering predicted obstacles
        local_command = self.local_planner.plan_local_motion(
            robot_state,
            goal,
            static_obstacles,
            predicted_obstacles
        )

        # If local planning finds immediate danger, use emergency maneuver
        if self.is_immediate_threat(robot_state, predicted_obstacles):
            local_command = self.emergency_maneuver(robot_state, predicted_obstacles)

        return local_command

    def predict_dynamic_obstacles(self, dynamic_obstacles, horizon):
        """Predict future positions of dynamic obstacles"""
        predicted_obstacles = []

        time_steps = int(horizon / 0.1)  # Predict every 0.1 seconds
        dt = 0.1

        for obs in dynamic_obstacles:
            # Simple constant velocity prediction
            for t in np.arange(0, horizon, dt):
                predicted_pos = (
                    obs['position'][0] + obs['velocity'][0] * t,
                    obs['position'][1] + obs['velocity'][1] * t
                )

                predicted_obstacles.append({
                    'position': predicted_pos,
                    'radius': obs['radius'],
                    'velocity': obs['velocity'],
                    'prediction_time': t,
                    'original_id': obs.get('id', 'unknown')
                })

        return predicted_obstacles

    def is_immediate_threat(self, robot_state, predicted_obstacles):
        """Check if there's an immediate threat from predicted obstacles"""
        robot_pos = robot_state[:2]

        for obs in predicted_obstacles:
            if obs['prediction_time'] < 1.0:  # Threat within 1 second
                dist = np.linalg.norm(np.array(robot_pos) - np.array(obs['position']))
                if dist < obs['radius'] + self.safety_margin + 0.5:  # 0.5m additional safety
                    return True

        return False

    def emergency_maneuver(self, robot_state, predicted_obstacles):
        """Execute emergency maneuver to avoid immediate threats"""
        # Find safest direction to move
        safe_directions = []

        # Check 8 directions around the robot
        for angle in np.linspace(0, 2*np.pi, 8, endpoint=False):
            direction = np.array([np.cos(angle), np.sin(angle)])
            test_pos = robot_state[:2] + direction * 0.5  # Move 0.5m in this direction

            # Check safety of this position
            min_dist = float('inf')
            for obs in predicted_obstacles:
                dist = np.linalg.norm(test_pos - np.array(obs['position']))
                min_dist = min(min_dist, dist)

            safe_directions.append((angle, min_dist))

        # Choose direction with maximum safety distance
        if safe_directions:
            best_direction = max(safe_directions, key=lambda x: x[1])
            best_angle = best_direction[0]

            # Convert to velocity commands
            linear_vel = 0.5  # Moderate speed for emergency maneuver
            angular_vel = best_angle - robot_state[2]  # Difference from current heading

            # Normalize angular velocity
            angular_vel = max(-1.0, min(1.0, angular_vel))

            return linear_vel, angular_vel

        # If no safe direction, just stop
        return 0.0, 0.0

class ObstaclePredictor:
    """Predictor for dynamic obstacle motion"""

    def __init__(self):
        self.obstacle_trackers = {}

    def update_obstacle_prediction(self, obstacle_id, position, velocity, timestamp):
        """Update prediction model for an obstacle"""
        if obstacle_id not in self.obstacle_trackers:
            self.obstacle_trackers[obstacle_id] = ObstacleTracker(obstacle_id)

        self.obstacle_trackers[obstacle_id].update(position, velocity, timestamp)

    def predict_position(self, obstacle_id, future_time):
        """Predict obstacle position at future time"""
        if obstacle_id in self.obstacle_trackers:
            return self.obstacle_trackers[obstacle_id].predict(future_time)
        return None

class ObstacleTracker:
    """Track and predict individual obstacle motion"""

    def __init__(self, obstacle_id):
        self.obstacle_id = obstacle_id
        self.positions = []
        self.velocities = []
        self.timestamps = []
        self.max_history = 10  # Keep last 10 measurements

    def update(self, position, velocity, timestamp):
        """Update tracker with new measurement"""
        self.positions.append(position)
        self.velocities.append(velocity)
        self.timestamps.append(timestamp)

        # Keep only recent history
        if len(self.positions) > self.max_history:
            self.positions.pop(0)
            self.velocities.pop(0)
            self.timestamps.pop(0)

    def predict(self, future_time):
        """Predict position at future time using current velocity model"""
        if not self.positions:
            return None

        # Use latest velocity for prediction
        current_pos = self.positions[-1]
        current_vel = self.velocities[-1]
        current_time = self.timestamps[-1]

        time_diff = future_time - current_time
        predicted_pos = (
            current_pos[0] + current_vel[0] * time_diff,
            current_pos[1] + current_vel[1] * time_diff
        )

        return predicted_pos
```

## Performance Optimization

### Hierarchical Planning

For large environments, hierarchical planning improves efficiency:

```python
class HierarchicalPlanner:
    """Hierarchical path planning for large-scale environments"""

    def __init__(self, environment_bounds, coarse_resolution=5.0, fine_resolution=0.1):
        self.environment_bounds = environment_bounds
        self.coarse_resolution = coarse_resolution
        self.fine_resolution = fine_resolution

        # Create coarse and fine grids
        self.coarse_grid = self.create_coarse_grid()
        self.fine_grid = None  # Will be set based on actual environment

    def create_coarse_grid(self):
        """Create coarse grid for high-level planning"""
        min_x, max_x = self.environment_bounds[0]
        min_y, max_y = self.environment_bounds[1]

        coarse_width = int((max_x - min_x) / self.coarse_resolution)
        coarse_height = int((max_y - min_y) / self.coarse_resolution)

        return np.zeros((coarse_height, coarse_width))

    def plan_hierarchical_path(self, start, goal, environment_grid):
        """
        Plan path using hierarchical approach:
        1. Plan coarse path on low-resolution grid
        2. Plan fine paths between coarse waypoints
        """
        # Convert start and goal to coarse grid coordinates
        coarse_start = self.world_to_coarse(start)
        coarse_goal = self.world_to_coarse(goal)

        # Plan coarse path
        coarse_path = self.plan_coarse_path(coarse_start, coarse_goal)

        if not coarse_path:
            return None

        # Convert coarse path to world coordinates and refine with fine planning
        refined_path = []
        current_pos = start

        for coarse_waypoint in coarse_path:
            # Convert coarse waypoint to world coordinates
            world_waypoint = self.coarse_to_world(coarse_waypoint)

            # Plan fine path from current position to coarse waypoint
            fine_path = self.plan_fine_path(current_pos, world_waypoint, environment_grid)

            if fine_path:
                # Add fine path to refined path (skip first point to avoid duplicates)
                if refined_path:
                    refined_path.extend(fine_path[1:])
                else:
                    refined_path.extend(fine_path)

                current_pos = world_waypoint
            else:
                # If fine planning fails, try alternative route
                alternative_path = self.find_alternative_route(current_pos, world_waypoint, environment_grid)
                if alternative_path:
                    if refined_path:
                        refined_path.extend(alternative_path[1:])
                    else:
                        refined_path.extend(alternative_path)
                    current_pos = world_waypoint
                else:
                    return None  # No path found

        # Add final segment to goal
        final_segment = self.plan_fine_path(current_pos, goal, environment_grid)
        if final_segment:
            refined_path.extend(final_segment[1:])

        return refined_path

    def world_to_coarse(self, world_pos):
        """Convert world coordinates to coarse grid coordinates"""
        min_x, _ = self.environment_bounds[0]
        min_y, _ = self.environment_bounds[1]

        coarse_x = int((world_pos[0] - min_x) / self.coarse_resolution)
        coarse_y = int((world_pos[1] - min_y) / self.coarse_resolution)

        return (coarse_x, coarse_y)

    def coarse_to_world(self, coarse_pos):
        """Convert coarse grid coordinates to world coordinates"""
        min_x, _ = self.environment_bounds[0]
        min_y, _ = self.environment_bounds[1]

        world_x = coarse_pos[0] * self.coarse_resolution + min_x + self.coarse_resolution / 2
        world_y = coarse_pos[1] * self.coarse_resolution + min_y + self.coarse_resolution / 2

        return (world_x, world_y)

    def plan_coarse_path(self, start, goal):
        """Plan path on coarse grid using A*"""
        # For simplicity, using a basic A* implementation
        # In practice, this would use a more efficient coarse planner
        planner = AStarPlanner(grid_resolution=self.coarse_resolution)

        # Create coarse grid with obstacles
        coarse_grid = self.create_coarse_grid_from_fine(environment_grid)

        return planner.plan_path(coarse_grid, start, goal)

    def create_coarse_grid_from_fine(self, fine_grid):
        """Create coarse grid by downsampling fine grid"""
        factor = int(self.coarse_resolution / self.fine_resolution)
        coarse_rows = fine_grid.shape[0] // factor
        coarse_cols = fine_grid.shape[1] // factor

        coarse_grid = np.zeros((coarse_rows, coarse_cols))

        # Downsample using majority voting
        for i in range(coarse_rows):
            for j in range(coarse_cols):
                fine_i_start = i * factor
                fine_i_end = min((i + 1) * factor, fine_grid.shape[0])
                fine_j_start = j * factor
                fine_j_end = min((j + 1) * factor, fine_grid.shape[1])

                # Check if majority of fine cells in this coarse cell are obstacles
                region = fine_grid[fine_i_start:fine_i_end, fine_j_start:fine_j_end]
                obstacle_ratio = np.sum(region == 1) / region.size

                if obstacle_ratio > 0.5:  # If more than 50% of fine cells are obstacles
                    coarse_grid[i, j] = 1

        return coarse_grid

    def plan_fine_path(self, start, goal, environment_grid):
        """Plan path on fine grid between two points"""
        fine_start = self.world_to_fine(start, environment_grid)
        fine_goal = self.world_to_fine(goal, environment_grid)

        planner = AStarPlanner(grid_resolution=self.fine_resolution)
        path_indices = planner.plan_path(environment_grid, fine_start, fine_goal)

        if path_indices:
            # Convert back to world coordinates
            world_path = [self.fine_to_world(pos, environment_grid) for pos in path_indices]
            return world_path

        return None

    def world_to_fine(self, world_pos, fine_grid):
        """Convert world coordinates to fine grid coordinates"""
        min_x, _ = self.environment_bounds[0]
        min_y, _ = self.environment_bounds[1]

        fine_x = int((world_pos[0] - min_x) / self.fine_resolution)
        fine_y = int((world_pos[1] - min_y) / self.fine_resolution)

        # Ensure coordinates are within grid bounds
        fine_x = max(0, min(fine_x, fine_grid.shape[1] - 1))
        fine_y = max(0, min(fine_y, fine_grid.shape[0] - 1))

        return (fine_y, fine_x)  # Note: y first for numpy array indexing

    def fine_to_world(self, fine_pos, fine_grid):
        """Convert fine grid coordinates to world coordinates"""
        min_x, _ = self.environment_bounds[0]
        min_y, _ = self.environment_bounds[1]

        world_x = fine_pos[1] * self.fine_resolution + min_x + self.fine_resolution / 2
        world_y = fine_pos[0] * self.fine_resolution + min_y + self.fine_resolution / 2

        return (world_x, world_y)

    def find_alternative_route(self, start, goal, environment_grid):
        """Find alternative route if primary path planning fails"""
        # This could implement various strategies:
        # 1. Try different coarse paths
        # 2. Use any-angle path planning
        # 3. Implement local obstacle avoidance

        # For now, return None - would implement sophisticated alternatives
        return None
```

## Safety-Critical Navigation

### Formal Verification for Safe Navigation

For safety-critical applications, formal verification methods can ensure safety properties:

```python
class SafetyVerifiedNavigator:
    """Safety-verified navigation system with formal guarantees"""

    def __init__(self, robot_model, safety_properties):
        self.robot_model = robot_model
        self.safety_properties = safety_properties
        self.verification_engine = SafetyVerificationEngine()
        self.safety_controller = SafetyController()

    def plan_safe_path(self, start, goal, environment, safety_level="standard"):
        """
        Plan path with formal safety guarantees
        Args:
            start: Start position [x, y, theta]
            goal: Goal position [x, y]
            environment: Environment representation with obstacles
            safety_level: "standard", "high", or "critical"
        Returns:
            Safe path or None if no safe path exists
        """
        # Set safety parameters based on level
        if safety_level == "critical":
            self.safety_controller.set_critical_safety_params()
        elif safety_level == "high":
            self.safety_controller.set_high_safety_params()
        else:
            self.safety_controller.set_standard_safety_params()

        # Plan initial path
        initial_path = self.plan_with_safety_constraints(start, goal, environment)

        if not initial_path:
            return None

        # Verify safety properties hold
        safety_checks = [
            self.verify_collision_avoidance(initial_path, environment),
            self.verify_dynamic_feasibility(initial_path),
            self.verify_stability_constraints(initial_path),
            self.verify_controllability(initial_path)
        ]

        if all(safety_checks):
            return initial_path
        else:
            # If safety verification fails, use more conservative planning
            conservative_path = self.plan_conservative_path(start, goal, environment)
            if conservative_path and self.verify_all_safety_properties(conservative_path, environment):
                return conservative_path
            else:
                return None  # No safe path possible

    def verify_collision_avoidance(self, path, environment):
        """Verify path avoids all obstacles"""
        robot_radius = self.robot_model.safety_radius

        for point in path:
            for obstacle in environment.get('obstacles', []):
                dist = np.sqrt((point[0] - obstacle['position'][0])**2 +
                              (point[1] - obstacle['position'][1])**2)
                if dist < obstacle['radius'] + robot_radius:
                    return False  # Collision detected

        return True

    def verify_dynamic_feasibility(self, path):
        """Verify path is dynamically feasible for robot"""
        # Check if path can be executed given robot's acceleration limits
        for i in range(1, len(path)):
            velocity = np.array(path[i][:2]) - np.array(path[i-1][:2])
            if np.linalg.norm(velocity) > self.robot_model.max_velocity:
                return False

        return True

    def verify_stability_constraints(self, path):
        """Verify path maintains robot stability"""
        # For mobile robots, check turning radius constraints
        # For manipulators, check joint limits and singularities
        for i in range(2, len(path)):
            # Calculate curvature between three consecutive points
            p1 = np.array(path[i-2][:2])
            p2 = np.array(path[i-1][:2])
            p3 = np.array(path[i][:2])

            # Calculate radius of curvature
            # Simplified calculation - in practice, this would be more complex
            v1 = p2 - p1
            v2 = p3 - p2
            angle_change = np.arccos(np.clip(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)), -1, 1))

            # Check if turning radius is within robot's capabilities
            if angle_change > self.robot_model.max_turn_rate:
                return False

        return True

    def verify_controllability(self, path):
        """Verify robot can follow the path"""
        # Check if robot can physically execute the planned trajectory
        # This involves checking joint limits, actuator capabilities, etc.
        return True  # Placeholder - would implement detailed checks

    def verify_all_safety_properties(self, path, environment):
        """Verify all safety properties for a path"""
        return (
            self.verify_collision_avoidance(path, environment) and
            self.verify_dynamic_feasibility(path) and
            self.verify_stability_constraints(path) and
            self.verify_controllability(path)
        )

    def plan_with_safety_constraints(self, start, goal, environment):
        """Plan path with explicit safety constraints"""
        # This would use constrained optimization or specialized safe planning algorithms
        # For now, using a standard planner with safety-checked path validation

        planner = AStarPlanner()
        potential_path = planner.plan_path(environment['grid'], start[:2], goal)

        if potential_path and self.verify_all_safety_properties(potential_path, environment):
            return potential_path

        return None

    def plan_conservative_path(self, start, goal, environment):
        """Plan more conservative path with larger safety margins"""
        # Inflate obstacles by additional safety margin
        conservative_env = self.create_conservative_environment(environment)

        return self.plan_with_safety_constraints(start, goal, conservative_env)

    def create_conservative_environment(self, environment):
        """Create conservative environment with increased safety margins"""
        conservative_env = environment.copy()

        # Inflate obstacles by additional safety margin
        additional_safety = 0.5  # 0.5m additional safety margin
        conservative_env['obstacles'] = [
            {
                'position': obs['position'],
                'radius': obs['radius'] + additional_safety
            }
            for obs in environment.get('obstacles', [])
        ]

        return conservative_env

class SafetyController:
    """Controller that ensures safety during execution"""

    def __init__(self):
        self.safety_params = {
            'collision_distance': 0.5,
            'max_approach_speed': 0.5,
            'emergency_braking': True,
            'safety_margin': 0.3
        }

    def set_critical_safety_params(self):
        """Set parameters for critical safety applications"""
        self.safety_params.update({
            'collision_distance': 1.0,  # 1m minimum distance
            'max_approach_speed': 0.2,  # Very slow near obstacles
            'emergency_braking': True,
            'safety_margin': 0.8        # Large safety margin
        })

    def set_high_safety_params(self):
        """Set parameters for high safety applications"""
        self.safety_params.update({
            'collision_distance': 0.7,
            'max_approach_speed': 0.3,
            'emergency_braking': True,
            'safety_margin': 0.5
        })

    def set_standard_safety_params(self):
        """Set standard safety parameters"""
        self.safety_params.update({
            'collision_distance': 0.5,
            'max_approach_speed': 0.5,
            'emergency_braking': True,
            'safety_margin': 0.3
        })

    def check_safety_violation(self, robot_state, sensor_data):
        """Check for safety violations based on sensor data"""
        # Check if robot is too close to obstacles
        for obs in sensor_data.get('obstacles', []):
            dist = np.sqrt((robot_state[0] - obs['position'][0])**2 +
                          (robot_state[1] - obs['position'][1])**2)

            if dist < self.safety_params['collision_distance']:
                return True, "Too close to obstacle"

        return False, "No safety violation"

class SafetyVerificationEngine:
    """Engine for formal safety verification"""

    def __init__(self):
        self.properties = []
        self.verification_methods = {
            'collision_free': self.verify_collision_free,
            'bounded_path': self.verify_bounded_path,
            'progress_made': self.verify_progress_made
        }

    def verify_collision_free(self, path, environment):
        """Verify path is collision-free"""
        # This would use formal methods like model checking or theorem proving
        # For now, using a simulation-based approach
        return True  # Placeholder

    def verify_bounded_path(self, path, environment):
        """Verify path stays within environment bounds"""
        min_x, max_x = environment['bounds'][0]
        min_y, max_y = environment['bounds'][1]

        for point in path:
            if not (min_x <= point[0] <= max_x and min_y <= point[1] <= max_y):
                return False

        return True

    def verify_progress_made(self, path, start, goal):
        """Verify path makes progress toward goal"""
        # Check that path doesn't wander aimlessly
        if len(path) < 2:
            return False

        # Calculate distance to goal at start and end of path
        start_dist = np.linalg.norm(np.array(start[:2]) - np.array(goal))
        end_dist = np.linalg.norm(np.array(path[-1][:2]) - np.array(goal))

        # Path should make progress (end closer to goal than start)
        return end_dist < start_dist + 1.0  # Allow some tolerance for path length
```

## Integration with Control Systems

### Model Predictive Path Integral Control (MPPI)

For stochastic optimal control in navigation:

```python
class MPPIController:
    """Model Predictive Path Integral controller for navigation"""

    def __init__(self, robot_model, horizon=15, num_samples=100,
                 noise_scale=0.1, lambda_param=1.0):
        self.robot_model = robot_model
        self.horizon = horizon
        self.num_samples = num_samples
        self.noise_scale = noise_scale
        self.lambda_param = lambda_param

    def compute_control(self, current_state, goal, environment, obstacles):
        """
        Compute control using MPPI
        Args:
            current_state: Current robot state [x, y, theta, v, omega]
            goal: Goal position [x, y]
            environment: Environment representation
            obstacles: List of obstacles
        Returns:
            Optimal control command
        """
        # Generate control sequences with noise
        control_sequences = self.generate_noisy_control_sequences()

        # Evaluate each sequence
        costs = []
        for seq in control_sequences:
            rollout_cost = self.evaluate_control_sequence(
                current_state.copy(), seq, goal, environment, obstacles
            )
            costs.append(rollout_cost)

        # Convert costs to weights (lower cost = higher weight)
        costs = np.array(costs)
        beta = np.min(costs)  # Shift for numerical stability
        weights = np.exp(-self.lambda_param * (costs - beta))

        # Normalize weights
        weights = weights / np.sum(weights)

        # Compute weighted average of first control inputs
        first_controls = np.array([seq[0] for seq in control_sequences])
        optimal_control = np.sum(weights[:, np.newaxis] * first_controls, axis=0)

        return optimal_control

    def generate_noisy_control_sequences(self):
        """Generate noisy control sequences for sampling"""
        sequences = []

        for _ in range(self.num_samples):
            # Start with zero-mean noise
            noise = np.random.normal(0, self.noise_scale, (self.horizon, 2))

            # Add bias toward nominal control (e.g., move toward goal)
            nominal_control = np.zeros((self.horizon, 2))

            # Combine nominal and noise
            control_seq = nominal_control + noise

            # Apply control limits
            control_seq[:, 0] = np.clip(control_seq[:, 0], -1.0, 1.0)  # Linear velocity
            control_seq[:, 1] = np.clip(control_seq[:, 1], -1.0, 1.0)  # Angular velocity

            sequences.append(control_seq)

        return sequences

    def evaluate_control_sequence(self, initial_state, control_sequence,
                                goal, environment, obstacles):
        """Evaluate cost of a control sequence"""
        state = initial_state.copy()
        total_cost = 0.0

        for i, control in enumerate(control_sequence):
            # Apply control and simulate forward
            next_state = self.simulate_step(state, control)

            # Calculate stage cost
            stage_cost = self.calculate_stage_cost(state, next_state, goal, obstacles)
            total_cost += stage_cost

            # Update state
            state = next_state

        # Add terminal cost
        terminal_cost = self.calculate_terminal_cost(state, goal)
        total_cost += terminal_cost

        return total_cost

    def simulate_step(self, state, control):
        """Simulate one step of robot dynamics"""
        # Simple differential drive model
        dt = 0.1  # Time step
        v, omega = control[0], control[1]

        new_state = state.copy()
        new_state[0] += v * np.cos(state[2]) * dt  # x
        new_state[1] += v * np.sin(state[2]) * dt  # y
        new_state[2] += omega * dt                # theta
        new_state[3] = v                          # v
        new_state[4] = omega                      # omega

        return new_state

    def calculate_stage_cost(self, state, next_state, goal, obstacles):
        """Calculate stage cost for current state"""
        cost = 0.0

        # Distance to goal (negative because we want to minimize distance)
        dist_to_goal = np.linalg.norm(np.array(state[:2]) - np.array(goal))
        cost += 0.1 * dist_to_goal

        # Control effort penalty
        v, omega = state[3], state[4]
        cost += 0.01 * (v**2 + omega**2)

        # Obstacle avoidance
        for obs in obstacles:
            obs_pos = obs['position'][:2]
            dist_to_obs = np.linalg.norm(np.array(state[:2]) - np.array(obs_pos))
            if dist_to_obs < obs['radius'] + 0.5:  # Safety margin
                cost += 1000 * max(0, (obs['radius'] + 0.5 - dist_to_obs))**2

        # Velocity penalty for moving too slowly when far from goal
        if dist_to_goal > 2.0 and abs(v) < 0.2:
            cost += 10.0  # Encourage movement when far from goal

        return cost

    def calculate_terminal_cost(self, state, goal):
        """Calculate terminal cost at end of horizon"""
        dist_to_goal = np.linalg.norm(np.array(state[:2]) - np.array(goal))
        return 100 * dist_to_goal  # High weight on reaching goal
```

### Integration with Navigation Stack

Putting it all together in a complete navigation system:

```python
class IntegratedNavigationSystem:
    """Complete integrated navigation system"""

    def __init__(self, robot_model, environment_bounds):
        self.robot_model = robot_model
        self.global_planner = AStarPlanner()
        self.local_planner = DynamicWindowApproach(robot_model)
        self.path_follower = PathFollowingController()
        self.obstacle_predictor = ObstaclePredictor()
        self.safety_controller = SafetyVerifiedNavigator(robot_model, {})
        self.hierarchical_planner = HierarchicalPlanner(environment_bounds)
        self.mppi_controller = MPPIController(robot_model)

        # Navigation state
        self.global_path = []
        self.current_waypoint = 0
        self.goal_reached = False
        self.navigation_active = False

    def navigate_to_goal(self, start_state, goal, environment,
                        use_hierarchical=True, safety_level="standard"):
        """
        Navigate robot from start to goal using integrated system
        Args:
            start_state: Starting state [x, y, theta, v, omega]
            goal: Goal position [x, y]
            environment: Environment with static and dynamic obstacles
            use_hierarchical: Whether to use hierarchical planning
            safety_level: Safety level for navigation
        Returns:
            Navigation status and execution metrics
        """
        self.navigation_active = True
        self.goal_reached = False

        # Plan global path
        if use_hierarchical:
            path = self.hierarchical_planner.plan_hierarchical_path(
                start_state[:2], goal, environment['grid']
            )
        else:
            path = self.global_planner.plan_path(
                environment['grid'], start_state[:2], goal
            )

        if not path:
            return {"status": "failure", "reason": "No path found"}

        self.global_path = path
        self.current_waypoint = 0

        # Verify path safety
        is_safe = self.safety_controller.verify_all_safety_properties(path, environment)
        if not is_safe and safety_level in ["high", "critical"]:
            # Try to find safe alternative
            safe_path = self.safety_controller.plan_safe_path(
                start_state[:2], goal, environment, safety_level
            )
            if safe_path:
                self.global_path = safe_path
            else:
                return {"status": "failure", "reason": "No safe path found"}

        # Execute navigation loop
        execution_metrics = self.execute_navigation_loop(start_state, goal, environment)

        self.navigation_active = False
        return execution_metrics

    def execute_navigation_loop(self, start_state, goal, environment):
        """Execute navigation in a control loop"""
        robot_state = start_state.copy()
        path_executed = []
        time_elapsed = 0.0
        collision_occurred = False
        max_time = 300.0  # 5 minute timeout

        while (not self.goal_reached and
               time_elapsed < max_time and
               self.navigation_active):

            # Check if goal is reached
            current_pos = robot_state[:2]
            goal_dist = np.linalg.norm(current_pos - np.array(goal))
            if goal_dist < 0.2:  # 20cm tolerance
                self.goal_reached = True
                break

            # Get local goal from global path
            local_goal = self.get_local_goal(robot_state, self.global_path)

            # Get dynamic obstacles
            dynamic_obstacles = environment.get('dynamic_obstacles', [])

            # Plan local motion using multiple approaches
            local_command = self.plan_local_motion(
                robot_state, local_goal, environment, dynamic_obstacles
            )

            # Execute command
            new_state = self.execute_control_command(robot_state, local_command)

            # Update state and record
            robot_state = new_state
            path_executed.append(robot_state.copy())
            time_elapsed += 0.1  # Assuming 10Hz control loop

            # Check for collisions
            if self.check_collision(robot_state, environment):
                collision_occurred = True
                break

        return {
            "status": "success" if self.goal_reached else "failure",
            "time_elapsed": time_elapsed,
            "path_length": self.calculate_path_length(path_executed),
            "collisions": 1 if collision_occurred else 0,
            "waypoints_tracked": len(path_executed),
            "final_distance_to_goal": np.linalg.norm(robot_state[:2] - np.array(goal)) if not self.goal_reached else 0
        }

    def get_local_goal(self, robot_state, global_path):
        """Get local goal from global path based on current position"""
        if not global_path:
            return robot_state[:2]  # Stay in place if no path

        # Find closest point on path
        robot_pos = robot_state[:2]
        min_dist = float('inf')
        closest_idx = 0

        for i, waypoint in enumerate(global_path):
            dist = np.linalg.norm(robot_pos - np.array(waypoint[:2]))
            if dist < min_dist:
                min_dist = dist
                closest_idx = i

        # Return a point ahead on the path
        lookahead_idx = min(closest_idx + 3, len(global_path) - 1)
        return global_path[lookahead_idx][:2]

    def plan_local_motion(self, robot_state, local_goal, environment, dynamic_obstacles):
        """Plan local motion using multiple strategies"""
        # Use local planner with dynamic obstacle prediction
        local_command = self.local_planner.plan_local_motion(
            robot_state, local_goal,
            environment.get('obstacles', []),
            dynamic_obstacles
        )

        # If local planner fails, use MPPI as fallback
        if local_command == (0.0, 0.0) and not self.is_stuck(robot_state):
            local_command = self.mppi_controller.compute_control(
                robot_state, local_goal, environment,
                environment.get('obstacles', [])
            )

        return local_command

    def execute_control_command(self, state, command):
        """Execute control command and return new state"""
        v, omega = command
        dt = 0.1  # Control loop time step

        new_state = state.copy()
        new_state[0] += v * np.cos(state[2]) * dt  # x
        new_state[1] += v * np.sin(state[2]) * dt  # y
        new_state[2] += omega * dt                # theta
        new_state[3] = v                          # v
        new_state[4] = omega                      # omega

        return new_state

    def check_collision(self, state, environment):
        """Check if current state is in collision"""
        robot_pos = state[:2]
        robot_radius = self.robot_model.safety_radius

        for obs in environment.get('obstacles', []):
            dist = np.linalg.norm(np.array(robot_pos) - np.array(obs['position'][:2]))
            if dist < obs['radius'] + robot_radius:
                return True

        return False

    def is_stuck(self, robot_state):
        """Check if robot is stuck"""
        # This would implement stuck detection logic
        # For example, checking if robot hasn't moved significantly in recent steps
        return False  # Placeholder

    def calculate_path_length(self, path):
        """Calculate total path length"""
        if len(path) < 2:
            return 0.0

        total_length = 0.0
        for i in range(1, len(path)):
            dist = np.linalg.norm(np.array(path[i][:2]) - np.array(path[i-1][:2]))
            total_length += dist

        return total_length
```

## Real-World Applications and Case Studies

### Autonomous Mobile Robot Navigation

Real-world implementation considerations:

```python
class AutonomousNavigationSystem:
    """Production-ready navigation system for autonomous robots"""

    def __init__(self, robot_config, map_manager, localization_system):
        self.robot_config = robot_config
        self.map_manager = map_manager
        self.localization = localization_system
        self.navigation_stack = IntegratedNavigationSystem(
            robot_config.model,
            robot_config.environment_bounds
        )

        # Navigation parameters
        self.nav_params = {
            'max_linear_speed': 1.0,
            'max_angular_speed': 1.0,
            'min_obstacle_dist': 0.5,
            'goal_tolerance': 0.2,
            'inflation_radius': 0.3,
            'recovery_enabled': True,
            'recovery_wait_time': 5.0
        }

    def execute_navigation(self, goal_pose):
        """Execute navigation to goal pose with full stack integration"""
        # Get current robot state from localization
        current_pose = self.localization.get_current_pose()
        if current_pose is None:
            return {"status": "failure", "reason": "Localization not available"}

        # Get current map from map manager
        current_map = self.map_manager.get_current_map()
        if current_map is None:
            return {"status": "failure", "reason": "Map not available"}

        # Plan and execute navigation
        environment = {
            'grid': current_map.grid,
            'obstacles': current_map.static_obstacles,
            'dynamic_obstacles': self.get_dynamic_obstacles(),
            'bounds': current_map.bounds
        }

        # Convert goal pose to simple coordinates for planning
        goal = (goal_pose.position.x, goal_pose.position.y)

        # Execute navigation with safety verification
        result = self.navigation_stack.navigate_to_goal(
            current_pose, goal, environment,
            use_hierarchical=True,
            safety_level="high"
        )

        return result

    def get_dynamic_obstacles(self):
        """Get dynamic obstacles from perception system"""
        # This would interface with perception system
        # to get real-time obstacle information
        return []

    def handle_navigation_recovery(self, failure_reason):
        """Handle navigation recovery in case of failure"""
        recovery_strategies = [
            self.try_clear_costmap,
            self.try_new_plan,
            self.rotate_in_place,
            self.small_movement
        ]

        for strategy in recovery_strategies:
            success = strategy()
            if success:
                return True

        return False

    def try_clear_costmap(self):
        """Try clearing the costmap to remove transient obstacles"""
        # Implementation would clear temporary obstacles from map
        return True

    def try_new_plan(self):
        """Try planning a new path around obstacles"""
        # Implementation would replan with updated obstacle information
        return True

    def rotate_in_place(self):
        """Try rotating in place to clear obstacles"""
        # Implementation would command robot to rotate and re-sense
        return True

    def small_movement(self):
        """Try small movement to get out of local minima"""
        # Implementation would command small movement in safe direction
        return True

# Example usage in a real robotic system
def main_navigation_loop():
    """Main navigation loop for autonomous robot"""
    # Initialize navigation system
    robot_config = RobotConfiguration()
    map_manager = MapManager()
    localization_system = LocalizationSystem()

    nav_system = AutonomousNavigationSystem(robot_config, map_manager, localization_system)

    # Main loop
    while True:
        # Get navigation goal (from higher-level planner or user command)
        goal = get_navigation_goal()

        if goal:
            # Execute navigation
            result = nav_system.execute_navigation(goal)

            if result['status'] == 'success':
                print("Navigation completed successfully")
            else:
                print(f"Navigation failed: {result['reason']}")

                # Try recovery if enabled
                if nav_system.nav_params['recovery_enabled']:
                    recovery_success = nav_system.handle_navigation_recovery(result['reason'])
                    if recovery_success:
                        print("Recovery successful, continuing navigation")
                    else:
                        print("Recovery failed, aborting navigation")

        # Sleep for control loop timing
        time.sleep(0.1)  # 10Hz control loop
```

## Challenges and Limitations

### Computational Complexity

Planning algorithms face significant computational challenges:

```python
class ComputationalOptimizer:
    """Optimization strategies for computationally expensive planning"""

    def __init__(self):
        self.cache = {}
        self.max_cache_size = 1000
        self.planning_budget = 0.1  # 100ms per planning step

    def plan_with_budget(self, planner_func, *args, **kwargs):
        """Plan with computational budget"""
        import time
        start_time = time.time()

        try:
            result = planner_func(*args, **kwargs)

            planning_time = time.time() - start_time
            if planning_time > self.planning_budget:
                print(f"Warning: Planning took {planning_time:.3f}s, budget was {self.planning_budget}s")

            return result
        except TimeoutError:
            return None

    def cache_planning_results(self, key, result):
        """Cache planning results to avoid recomputation"""
        if len(self.cache) >= self.max_cache_size:
            # Remove oldest entry
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]

        self.cache[key] = result

    def get_cached_result(self, key):
        """Get cached planning result"""
        return self.cache.get(key)
```

### Multi-Modal Integration

Combining different navigation modalities:

```python
class MultiModalNavigation:
    """Navigation using multiple modalities (ground, aerial, etc.)"""

    def __init__(self, modalities):
        self.modalities = modalities  # List of navigation modality planners
        self.modality_selector = ModalitySelector()

    def plan_multimodal_path(self, start, goal, environment):
        """Plan path that may use multiple navigation modalities"""
        # Determine which modalities are applicable for this environment
        applicable_modalities = self.determine_applicable_modalities(start, goal, environment)

        # Plan path using each applicable modality
        modality_paths = {}
        for modality in applicable_modalities:
            path = modality.plan_path(start, goal, environment)
            if path:
                cost = self.evaluate_path_cost(path, modality)
                modality_paths[modality.name] = (path, cost)

        # Select optimal modality or combination
        if modality_paths:
            best_modality = min(modality_paths.keys(), key=lambda k: modality_paths[k][1])
            return modality_paths[best_modality][0]

        # If single modality fails, try multimodal path with transitions
        return self.plan_with_modality_transitions(start, goal, environment)

    def determine_applicable_modalities(self, start, goal, environment):
        """Determine which navigation modalities are applicable"""
        applicable = []

        for modality in self.modalities:
            if modality.can_navigate(start, goal, environment):
                applicable.append(modality)

        return applicable

    def evaluate_path_cost(self, path, modality):
        """Evaluate cost of path for specific modality"""
        # Cost factors: path length, energy consumption, time, safety
        path_length = self.calculate_path_length(path)
        energy_cost = path_length * modality.energy_per_unit
        time_cost = path_length / modality.max_speed
        safety_cost = self.calculate_safety_cost(path, modality, environment)

        return path_length + energy_cost + time_cost + safety_cost

    def plan_with_modality_transitions(self, start, goal, environment):
        """Plan path with transitions between different navigation modalities"""
        # This would implement complex multimodal planning
        # For example: ground robot to a point, then aerial robot for obstacle crossing
        return None  # Placeholder
```

## Performance Evaluation and Metrics

### Navigation Performance Metrics

```python
class NavigationEvaluator:
    """Evaluation framework for navigation algorithms"""

    def __init__(self, environment, robot_model):
        self.environment = environment
        self.robot_model = robot_model
        self.metrics = {
            'success_rate': [],
            'path_efficiency': [],  # Ratio of actual path length to optimal
            'time_to_completion': [],
            'energy_consumption': [],
            'safety_violations': [],
            'computational_efficiency': [],  # Planning time per step
            'smoothness': [],  # Path smoothness measure
            'robustness': []    # Success rate under perturbations
        }

    def evaluate_planner(self, planner, test_cases: List[dict]) -> dict:
        """Evaluate planner on test cases"""
        for test_case in test_cases:
            result = self.run_test_case(planner, test_case)
            self.aggregate_results(result)

        return self.compute_summary_statistics()

    def run_test_case(self, planner, test_case: dict) -> dict:
        """Run a single test case and return results"""
        start_time = time.time()
        start_pos = test_case['start']
        goal_pos = test_case['goal']
        environment = test_case['environment']

        # Plan path
        path = planner.plan_path(start_pos, goal_pos, environment)

        # Execute path and collect metrics
        execution_result = self.execute_path(path, environment)

        # Compute metrics
        metrics = {
            'success': execution_result['success'],
            'path_length': execution_result['path_length'],
            'execution_time': time.time() - start_time,
            'collisions': execution_result['collisions'],
            'energy_used': execution_result['energy_used']
        }

        return metrics

    def execute_path(self, path: List[Tuple[float, float]], environment: dict) -> dict:
        """Execute path in environment and collect metrics"""
        if not path:
            return {
                'success': False,
                'path_length': 0,
                'collisions': 0,
                'energy_used': 0
            }

        total_length = 0
        collisions = 0
        energy_used = 0
        current_pos = path[0]

        for next_pos in path[1:]:
            # Calculate segment length
            segment_length = np.linalg.norm(np.array(next_pos) - np.array(current_pos))
            total_length += segment_length

            # Check for collisions
            if self.check_collision(current_pos, next_pos, environment):
                collisions += 1

            # Calculate energy (simplified)
            energy_used += segment_length * self.estimate_energy_cost(current_pos, next_pos)

            current_pos = next_pos

        return {
            'success': len(path) > 1,  # Non-empty path indicates success
            'path_length': total_length,
            'collisions': collisions,
            'energy_used': energy_used
        }

    def check_collision(self, pos1: Tuple[float, float], pos2: Tuple[float, float],
                       environment: dict) -> bool:
        """Check for collision along path segment"""
        # Check if path segment intersects with any obstacles
        obstacles = environment.get('obstacles', [])

        for obstacle in obstacles:
            if self.segment_intersects_circle(pos1, pos2, obstacle['position'][:2], obstacle['radius']):
                return True

        return False

    def segment_intersects_circle(self, p1: Tuple[float, float], p2: Tuple[float, float],
                                 center: Tuple[float, float], radius: float) -> bool:
        """Check if line segment intersects with circle"""
        p1 = np.array(p1)
        p2 = np.array(p2)
        center = np.array(center)

        # Vector from p1 to p2
        d = p2 - p1
        # Vector from p1 to circle center
        f = p1 - center

        # Quadratic equation coefficients
        a = np.dot(d, d)
        b = 2 * np.dot(f, d)
        c = np.dot(f, f) - radius * radius

        discriminant = b * b - 4 * a * c

        if discriminant < 0:
            # No intersection
            return False
        else:
            # Check if intersection points are within the segment
            sqrt_discriminant = np.sqrt(discriminant)
            t1 = (-b - sqrt_discriminant) / (2 * a)
            t2 = (-b + sqrt_discriminant) / (2 * a)

            # Check if either t1 or t2 is in [0, 1] (within segment)
            return (0 <= t1 <= 1) or (0 <= t2 <= 1)

    def estimate_energy_cost(self, pos1: Tuple[float, float], pos2: Tuple[float, float]) -> float:
        """Estimate energy cost of moving between two positions"""
        # Simplified energy model - in reality this would consider:
        # - Terrain type and roughness
        # - Robot dynamics
        # - Actuator efficiency
        # - Payload
        distance = np.linalg.norm(np.array(pos2) - np.array(pos1))
        return distance * 0.1  # Placeholder energy cost

    def aggregate_results(self, result: dict):
        """Aggregate results from test case"""
        self.metrics['success_rate'].append(result['success'])
        self.metrics['time_to_completion'].append(result['execution_time'])
        self.metrics['safety_violations'].append(result['collisions'])

    def compute_summary_statistics(self) -> dict:
        """Compute summary statistics from metrics"""
        return {
            'success_rate': np.mean(self.metrics['success_rate']) if self.metrics['success_rate'] else 0,
            'avg_execution_time': np.mean(self.metrics['time_to_completion']) if self.metrics['time_to_completion'] else 0,
            'avg_safety_violations': np.mean(self.metrics['safety_violations']) if self.metrics['safety_violations'] else 0,
            'std_execution_time': np.std(self.metrics['time_to_completion']) if self.metrics['time_to_completion'] else 0
        }
```

## Summary

Planning and navigation in Physical AI systems requires sophisticated algorithms that can handle the complexities of real-world environments. Unlike digital systems that can compute optimal paths in idealized environments, Physical AI systems must navigate through continuous, dynamic, and uncertain physical spaces. This chapter explored classical algorithms like A* and Dijkstra's, sampling-based methods like RRT*, local planning approaches like DWA, and advanced techniques for handling dynamic environments and multiple agents.

The key challenges in Physical AI navigation include computational efficiency, safety assurance, real-time constraints, and the need to integrate with perception and control systems. Successful navigation systems must balance multiple competing objectives: reaching goals efficiently while maintaining safety, adapting to dynamic environments, and operating within physical constraints.

Modern navigation approaches increasingly leverage machine learning for adaptive planning, with techniques like reinforcement learning for local navigation and learning-based path optimization. The integration of these approaches with classical methods provides the robustness and efficiency needed for real-world deployment.

As Physical AI systems become more sophisticated, navigation algorithms will need to become more adaptive, efficient, and capable of handling the increasing complexity of real-world robotic applications. The future of navigation in Physical AI lies in the seamless integration of planning, perception, and control, creating systems that can operate reliably in diverse and challenging environments.

## Key Takeaways

- Physical navigation requires algorithms that account for real-time constraints and environmental uncertainties
- Different communication patterns serve specific purposes in navigation (topics for streaming, services for queries, actions for goals)
- Hierarchical planning improves efficiency for large-scale environments
- Safety verification is crucial for physical system deployment
- Multi-modal navigation enables robots to adapt to diverse environments
- Real-time obstacle avoidance requires efficient local planning algorithms
- Integration with perception and SLAM enables navigation in unknown environments
- Performance evaluation must consider both computational and physical metrics
- Dynamic environment navigation requires predictive models and reactive planning

## References and Further Reading

1. "Planning Algorithms" - LaValle
2. "Principles of Robot Motion" - Choset et al.
3. "Robot Motion Planning" - Latombe
4. "Probabilistic Robotics" - Thrun, Burgard & Fox
5. "Handbook of Robotics" - Siciliano & Khatib
6. "Multi-Robot Systems: From Swarms to Intelligent Automata" - Parker et al.
7. "Path Planning in Robotics" - Recent developments and challenges
8. "A Survey of Motion Planning and Control Techniques for Robot Navigation" - Technical survey